{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from tableone import TableOne\n",
    "from statannotations.Annotator import Annotator\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "import itertools\n",
    "import statannotations\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "\n",
    "# Configure matplotlib and seaborn for consistent plotting style\n",
    "plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans', 'sans-serif']\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"Pastel1\")\n",
    "\n",
    "pastel_rainbow = [\n",
    "    \"#F0C2C2\",  # soft coral pink\n",
    "    \"#F0D2B8\",  # soft peach\n",
    "    \"#FFFFBA\",  # soft butter yellow\n",
    "    \"#C2F0C8\",  # soft mint green\n",
    "    \"#C2D8F0\",  # soft sky blue\n",
    "    \"#D8C2F0\"   # soft lilac\n",
    "]\n",
    "\n",
    "# Show 100 rows in pandas dataframes by default\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Print Python and package versions for reproducibility\n",
    "print(f'Python: {sys.version}')\n",
    "\n",
    "packages = [\n",
    "    ('pandas', 'pd'),\n",
    "    ('matplotlib', 'matplotlib'), \n",
    "    ('seaborn', 'sns'),\n",
    "    ('scipy', 'scipy'),\n",
    "    ('tableone', 'tableone'),\n",
    "    ('statannotations', 'statannotations'),\n",
    "    ('numpy', 'np')\n",
    "]\n",
    "\n",
    "for package_name, import_name in packages:\n",
    "    try:\n",
    "        module = __import__(package_name)\n",
    "        print(f'{package_name}: {module.__version__}')\n",
    "    except Exception as e:\n",
    "        print(f'{package_name}: Error - {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ExaminingExperiences_DATA_LABELS_2025-07-09_0751_deid_cleaned.csv', index_col=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify 'multiple_interviews' column\n",
    "df['multiple_interviews'] = (\n",
    "    ((df['Did you interview at and receive offers from multiple institutions?'].fillna('') == 'Yes') |\n",
    "     (df['Did you interview at and receive offers from multiple institutions?.1'].fillna('') == 'Yes'))\n",
    "    &\n",
    "    (df['Did you interview at and receive offers from multiple institutions?'].fillna('') != 'None') &\n",
    "    (df['Did you interview at and receive offers from multiple institutions?.1'].fillna('') != 'None')\n",
    ")\n",
    "df.groupby('Type of Job Most Recently Accepted')['multiple_interviews'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'extra_degree' column\n",
    "df['extra_degree'] = (\n",
    "    (df['Degrees Held (Select all that apply) (choice=MS (including MSCE, MSCI, MSci, MPH, etc.))'] == 'Checked') |\n",
    "    (df['Degrees Held (Select all that apply) (choice=PhD)'] == 'Checked')\n",
    ")\n",
    "df['extra_degree'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'gender' column\n",
    "df['gender'] = df['Gender'].replace('Prefer not to answer', np.nan)\n",
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Unchecked' with NaN and create a main copy\n",
    "df = df.replace('Unchecked', np.nan)\n",
    "df_main = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TableOne - Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics TableOne by respondent\n",
    "columns = [\n",
    " 'Gender',\n",
    "  'Degrees Held (Select all that apply) (choice=MD, DO, MBBS or equivalent)',\n",
    " 'Degrees Held (Select all that apply) (choice=MS (including MSCE, MSCI, MSci, MPH, etc.))',\n",
    " 'Degrees Held (Select all that apply) (choice=PhD)',\n",
    "  'Race/Ethnicity (Select all that apply) (choice=Asian or Asian American)',\n",
    " 'Race/Ethnicity (Select all that apply) (choice=Black or African American)',\n",
    " 'Race/Ethnicity (Select all that apply) (choice=Hispanic, Latino, Latina, or LatinX)',\n",
    " 'Race/Ethnicity (Select all that apply) (choice=White)',\n",
    " 'Race/Ethnicity (Select all that apply) (choice=Other)',\n",
    " 'Race/Ethnicity (Select all that apply) (choice=Prefer not to answer)',\n",
    "  'Do you identify as underrepresented in medicine?',\n",
    " 'Did you accept a job at the same institution where you completed fellowship training?',\n",
    " 'multiple_interviews',\n",
    "   'Type of Research (select all that apply) (choice=Basic)',\n",
    " 'Type of Research (select all that apply) (choice=Translational)',\n",
    " 'Type of Research (select all that apply) (choice=Clinical)',\n",
    " 'Type of Research (select all that apply) (choice=Computational (only dry lab))',\n",
    " 'Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?',\n",
    "]\n",
    "\n",
    "table1 = TableOne(df, columns=columns, categorical=columns, missing=False,\n",
    "                  rename=None, groupby='Type of Job Most Recently Accepted', pval=True)\n",
    "table1.to_csv('table1_demographics.csv')\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting and Cleaning for Physician Scientist (PS) and Clinician Educator (CE) Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by PS CE\n",
    "df_scientist = df_main[df_main['Type of Job Most Recently Accepted'] == 'Physician scientist'].copy()\n",
    "df_educator = df_main[df_main['Type of Job Most Recently Accepted'] == 'Clinician educator'].copy()\n",
    "\n",
    "# Drop columns where all values are NaN or empty strings for df_scientist\n",
    "df_scientist = df_scientist.dropna(axis=1, how='all')         # Remove columns that are all NaN\n",
    "df_scientist = df_scientist.loc[:, ~(df_scientist == '').all()]  # Remove columns that are all empty strings\n",
    "df_scientist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop from df_scientist\n",
    "columns_to_drop = [\n",
    "    \"Do you agree to participate in this survey? By clicking 'I Agree', you are consenting to participate in this survey. \",\n",
    "    'Degrees Held (Select all that apply) (choice=MD, DO, MBBS or equivalent)',\n",
    "    'Degrees Held (Select all that apply) (choice=MS (including MSCE, MSCI, MSci, MPH, etc.))',\n",
    "    'Degrees Held (Select all that apply) (choice=PhD)',\n",
    "    'Degrees Held (Select all that apply) (choice=Other)',\n",
    "    'If Other for Degrees Held, please specify:',\n",
    "    'Gender',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=Asian or Asian American)',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=Hispanic, Latino, Latina, or LatinX)',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=White)',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=Prefer not to answer)'\n",
    "]\n",
    "\n",
    "# Drop the columns (only drop columns that actually exist in the dataframe)\n",
    "columns_to_drop_existing = [col for col in columns_to_drop if col in df_scientist.columns]\n",
    "df_scientist = df_scientist.drop(columns=columns_to_drop_existing)\n",
    "\n",
    "print(f\"Dropped {len(columns_to_drop_existing)} columns from df_scientist\")\n",
    "print(f\"Remaining columns: {df_scientist.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns where all values are NaN or empty strings for df_educator\n",
    "df_educator = df_educator.dropna(axis=1, how='all')         # Remove columns that are all NaN\n",
    "df_educator = df_educator.loc[:, ~(df_educator == '').all()]  # Remove columns that are all empty strings\n",
    "df_educator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop from df_educator\n",
    "columns_to_drop = [\n",
    "    \"Do you agree to participate in this survey? By clicking 'I Agree', you are consenting to participate in this survey. \",\n",
    "    'Degrees Held (Select all that apply) (choice=MD, DO, MBBS or equivalent)',\n",
    "    'Degrees Held (Select all that apply) (choice=MS (including MSCE, MSCI, MSci, MPH, etc.))',\n",
    "    'Degrees Held (Select all that apply) (choice=PhD)',\n",
    "    'Degrees Held (Select all that apply) (choice=Other)',\n",
    "    'If Other for Degrees Held, please specify:',\n",
    "    'Gender',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=Asian or Asian American)',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=Hispanic, Latino, Latina, or LatinX)',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=White)',\n",
    "    'Race/Ethnicity (Select all that apply) (choice=Prefer not to answer)'\n",
    "]\n",
    "\n",
    "# Drop the columns (only drop columns that actually exist in the dataframe)\n",
    "columns_to_drop_existing = [col for col in columns_to_drop if col in df_educator.columns]\n",
    "df_educator = df_educator.drop(columns=columns_to_drop_existing)\n",
    "\n",
    "print(f\"Dropped {len(columns_to_drop_existing)} columns from df_educator\")\n",
    "print(f\"Remaining columns: {df_educator.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-check shape after dropping columns (redundant, but kept for consistency with original notebook)\n",
    "df_educator = df_educator.dropna(axis=1, how='all')         # Remove columns that are all NaN\n",
    "df_educator = df_educator.loc[:, ~(df_educator == '').all()]  # Remove columns that are all empty strings\n",
    "df_educator.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS Job Offer Melting and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_job_offers_ps(df_scientist):\n",
    "    \"\"\"\n",
    "    Melt job offer columns from wide to long format for Physician Scientists.\n",
    "    Each respondent can have up to 3 job offers (base, .1, .2 suffixes).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the base column names (without suffixes)\n",
    "    base_columns = [\n",
    "        'What salary range were you offered?',\n",
    "        'What were you offered for protected research time?',\n",
    "        'What geographic region is the institution?',\n",
    "        'Cost of living at institution (example cities)',\n",
    "        'Did you receive or negotiate a startup package as part of your appointment?',\n",
    "        'If yes, what is the approximate value of your startup package?',\n",
    "        'Did the startup package have salary cost-sharing? (e.g., your grant does not cover all your salary and hence you need to pay the differential via your startup funds)',\n",
    "        'Were any signing bonuses or performance-based incentives part of your negotiation?',\n",
    "        'If yes, what is the approximate total value of these bonuses/incentives?',\n",
    "        'Were you offered a relocation package?',\n",
    "        'If yes, what was the total value of the relocation package?',\n",
    "        'Do you have a noncompete clause?',\n",
    "    ]\n",
    "    \n",
    "    # Get all non-job-offer columns (these will be preserved for each respondent)\n",
    "    job_offer_columns = []\n",
    "    for base_col in base_columns:\n",
    "        job_offer_columns.extend([base_col, base_col + '.1', base_col + '.2'])\n",
    "    \n",
    "    # Identify columns that are NOT job offer columns\n",
    "    id_columns = [col for col in df_scientist.columns if col not in job_offer_columns]\n",
    "    \n",
    "    # Create separate dataframes for each job offer\n",
    "    dfs_to_concat = []\n",
    "    \n",
    "    for offer_num, suffix in enumerate(['', '.1', '.2']):\n",
    "        # Get columns for this job offer\n",
    "        offer_columns = {}\n",
    "        for base_col in base_columns:\n",
    "            full_col = base_col + suffix\n",
    "            if full_col in df_scientist.columns:\n",
    "                offer_columns[full_col] = base_col\n",
    "        \n",
    "        if offer_columns:  # Only process if columns exist\n",
    "            # Select ID columns + this offer's columns\n",
    "            cols_to_select = id_columns + list(offer_columns.keys())\n",
    "            df_offer = df_scientist[cols_to_select].copy()\n",
    "            \n",
    "            # Rename columns to remove suffixes\n",
    "            df_offer = df_offer.rename(columns=offer_columns)\n",
    "            \n",
    "            # Add job offer number\n",
    "            df_offer['job_offer_number'] = offer_num + 1\n",
    "            \n",
    "            # Remove rows where all job offer columns are null\n",
    "            job_cols_mask = df_offer[base_columns].notna().any(axis=1)\n",
    "            df_offer = df_offer[job_cols_mask]\n",
    "            \n",
    "            dfs_to_concat.append(df_offer)\n",
    "    \n",
    "    # Concatenate all job offers\n",
    "    df_melted = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "    \n",
    "    # Sort by respondent identifier and job offer number\n",
    "    # If you have a respondent ID column, replace 'index' with that column name\n",
    "    if 'respondent_id' in df_melted.columns:\n",
    "        df_melted = df_melted.sort_values(['respondent_id', 'job_offer_number'])\n",
    "    else:\n",
    "        # If no explicit ID, sort by index and job offer number\n",
    "        df_melted = df_melted.sort_values(['job_offer_number'])\n",
    "    \n",
    "    return df_melted\n",
    "\n",
    "# Example usage:\n",
    "df_scientist_melted = melt_job_offers_ps(df_scientist)\n",
    "print(f\"Original shape: {df_scientist.shape}\")\n",
    "print(f\"Melted shape: {df_scientist_melted.shape}\")\n",
    "print(f\"Number of unique job offers: {len(df_scientist_melted)}\")\n",
    "df_scientist_melted.job_offer_number.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist_melted.to_csv('df_scientist_melted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free text columns to drop from df_scientist_melted\n",
    "freetext_columns_to_drop = [\n",
    "    \"Do you agree to participate in this survey? By clicking 'I Agree', you are consenting to participate in this survey.  \",\n",
    "    'If yes, please provide details regarding radius, buyout, and time frame.',\n",
    "    'Why did you choose to accept this job over other offers?',\n",
    "    'Would you like to add any additional comments about this first job offer?',\n",
    "    'If yes, please provide details regarding radius, buyout, and time frame..1',\n",
    "    'Would you like to add any additional comments about this second job offer?',\n",
    "    'Did you interview at and receive offers from yet another institution?',\n",
    "    'If yes, please provide details regarding radius, buyout, and time frame..2',\n",
    "    'Did you interview at and receive offers from yet another institution? (You will not be asked to complete another set of questions.)',\n",
    "    'Complete?'\n",
    "]\n",
    "\n",
    "# Drop the columns (only drop columns that actually exist in the dataframe)\n",
    "freetext_columns_existing = [col for col in freetext_columns_to_drop if col in df_scientist_melted.columns]\n",
    "df_scientist_melted = df_scientist_melted.drop(columns=freetext_columns_existing)\n",
    "\n",
    "print(f\"Dropped {len(freetext_columns_existing)} free text columns from df_scientist_melted\")\n",
    "print(f\"Remaining columns: {df_scientist_melted.shape[1]}\")\n",
    "print(f\"Remaining rows: {df_scientist_melted.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TableOne Generation - PS Job Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [     'What salary range were you offered?',\n",
    "       'What were you offered for protected research time?',\n",
    "       'What geographic region is the institution?',\n",
    "       'Cost of living at institution (example cities)',\n",
    "       'Did you receive or negotiate a startup package as part of your appointment?',\n",
    "       'If yes, what is the approximate value of your startup package?',\n",
    "       'Did the startup package have salary cost-sharing? (e.g., your grant does not cover all your salary and hence you need to pay the differential via your startup funds)',\n",
    "       'Were any signing bonuses or performance-based incentives part of your negotiation?',\n",
    "       'If yes, what is the approximate total value of these bonuses/incentives?',\n",
    "       'Were you offered a relocation package?',\n",
    "       'If yes, what was the total value of the relocation package?',\n",
    "       'Do you have a noncompete clause?', 'job_offer_number']\n",
    "\n",
    "\n",
    "\n",
    "# Generate TableOne\n",
    "table1 = TableOne(df_scientist_melted, columns=columns, categorical=columns,  rename=None, groupby=\n",
    " 'Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?', pval=True)\n",
    "table1.to_csv('table1_job_offers_scientist_byK.csv')\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS Job Offer Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix stayed at same institution flag\n",
    "df_scientist_melted['Did you accept a job at the same institution where you completed fellowship training?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist_melted['internal_offer'] = ((df_scientist_melted['Did you accept a job at the same institution where you completed fellowship training?'] == 'Yes') & \n",
    "                              (df_scientist_melted['job_offer_number'] == 1)).apply(lambda x: True if x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist_melted['internal_offer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ordered categories for salary\n",
    "salary_categories = [\n",
    "    'Less than $150,000',\n",
    "    '$150,000-$199,999',\n",
    "    '$200,000-$249,999',\n",
    "    '$250,000-$299,999',\n",
    "    'More than $300,000'\n",
    "]\n",
    "\n",
    "# Convert to categorical with ordering\n",
    "df_scientist_melted['salary_range_offered'] = pd.Categorical(df_scientist_melted['What salary range were you offered?'], categories=salary_categories, ordered=True)\n",
    "\n",
    "salary_map = {\n",
    "    'Less than $150,000': 1,\n",
    "    '$150,000-$199,999': 2,\n",
    "    '$200,000-$249,999': 3,\n",
    "    '$250,000-$299,999': 4,\n",
    "    'More than $300,000': 5\n",
    "}\n",
    "\n",
    "df_scientist_melted['salary_ordinal'] = df_scientist_melted['salary_range_offered'].map(salary_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS Salary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_bar_with_stats(data, x_col, y_col, order=None, pairs=None, \n",
    "                                 test='Mann-Whitney', loc='outside', \n",
    "                                 text_format='simple', figsize=(7, 4), title=None, xlabel=None):\n",
    "    \n",
    "    # Create salary mapping\n",
    "    salary_map = {\n",
    "        'Less than $150,000': 1,\n",
    "        '$150,000-$199,999': 2,\n",
    "        '$200,000-$249,999': 3,\n",
    "        '$250,000-$299,999': 4,\n",
    "        'More than $300,000': 5\n",
    "    }\n",
    "    \n",
    "    # Create reverse mapping for labels\n",
    "    reverse_salary_map = {v: k for k, v in salary_map.items()}\n",
    "    \n",
    "    # Prepare data for stacked bar chart\n",
    "    df_plot = data.copy()\n",
    "    df_plot['salary_range'] = df_plot[y_col].map(reverse_salary_map)\n",
    "    \n",
    "    # Create crosstab for stacked bar chart\n",
    "    crosstab = pd.crosstab(df_plot[x_col], df_plot['salary_range'])\n",
    "    \n",
    "    # Reorder columns based on salary_ordinal order\n",
    "    salary_order = [reverse_salary_map[i] for i in sorted(reverse_salary_map.keys())]\n",
    "    crosstab = crosstab.reindex(columns=salary_order, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "\n",
    "    # Create the stacked bar plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax,\n",
    "                       color=pastel_rainbow)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(xlabel or x_col)\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_title(title or f'Distribution of Salary Ranges by {x_col}')\n",
    "    ax.set_ylim(0, 1)  # Set y-axis from 0 to 1 for proportions\n",
    "    \n",
    "    # Fix legend order to match stacking order (flip it)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title='Salary Range', \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    # Add statistical annotation if pairs are provided\n",
    "    if pairs:\n",
    "        annotator = Annotator(ax, pairs, data=data, x=x_col, y=y_col, order=order)\n",
    "        annotator.configure(test=test, loc=loc, text_format=text_format)\n",
    "        annotator.apply_and_annotate()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "# Create plot for K08/K23 grant status vs. salary\n",
    "fig, ax = create_stacked_bar_with_stats(\n",
    "    data=df_scientist_melted, \n",
    "    x_col='Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?',\n",
    "    y_col='salary_ordinal', \n",
    "    order=['No','Yes'],\n",
    "    pairs=[('No','Yes')],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges',\n",
    "    xlabel='K08/K23 already?'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_type_columns = [\n",
    "    'Type of Research (select all that apply) (choice=Basic)',\n",
    "    'Type of Research (select all that apply) (choice=Translational)', \n",
    "    'Type of Research (select all that apply) (choice=Clinical)',\n",
    "    'Type of Research (select all that apply) (choice=Computational (only dry lab))'\n",
    "]\n",
    "\n",
    "# Shorter labels for plotting\n",
    "research_labels = {\n",
    "    'Type of Research (select all that apply) (choice=Basic)': 'Basic\\nResearch',\n",
    "    'Type of Research (select all that apply) (choice=Translational)': 'Translational\\nResearch',\n",
    "    'Type of Research (select all that apply) (choice=Clinical)': 'Clinical\\nResearch',\n",
    "    'Type of Research (select all that apply) (choice=Computational (only dry lab))': 'Computational\\nResearch'\n",
    "}\n",
    "\n",
    "# Define salary categories in order\n",
    "salary_categories = [\n",
    "    'Less than $150,000',\n",
    "    '$150,000-$199,999',\n",
    "    '$200,000-$249,999',\n",
    "    '$250,000-$299,999',\n",
    "    'More than $300,000'\n",
    "]\n",
    "\n",
    "# Create salary mapping\n",
    "salary_map = {\n",
    "    'Less than $150,000': 1,\n",
    "    '$150,000-$199,999': 2,\n",
    "    '$200,000-$249,999': 3,\n",
    "    '$250,000-$299,999': 4,\n",
    "    'More than $300,000': 5\n",
    "}\n",
    "\n",
    "# Create reverse mapping for labels\n",
    "reverse_salary_map = {v: k for k, v in salary_map.items()}\n",
    "\n",
    "def create_combined_research_salary_plot(data, salary_col):\n",
    "    \"\"\"Create a single plot with stacked bars for each research type showing salary distribution\"\"\"\n",
    "    \n",
    "    # Check which columns actually exist\n",
    "    existing_research_cols = [col for col in research_type_columns if col in data.columns]\n",
    "    print(f\"Found {len(existing_research_cols)} research type columns in data\")\n",
    "    \n",
    "    if len(existing_research_cols) == 0:\n",
    "        print(\"No research type columns found!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Prepare data for all research types\n",
    "    all_proportions = []\n",
    "    research_names = []\n",
    "    sample_sizes = []\n",
    "    \n",
    "    for research_col in existing_research_cols:\n",
    "        # Filter data for this research type where value is 'Checked'\n",
    "        try:\n",
    "            research_mask = data[research_col] == 'Checked'\n",
    "            research_data = data[research_mask].copy()\n",
    "        except Exception as e:\n",
    "            print(f\"Error filtering {research_col}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if len(research_data) == 0:\n",
    "            print(f\"No data for {research_col}\")\n",
    "            continue\n",
    "        \n",
    "        # Create value counts for salary ranges\n",
    "        # If using ordinal values, convert back to text labels\n",
    "        if salary_col == 'salary_ordinal':\n",
    "            # Map ordinal values back to text labels\n",
    "            research_data_mapped = research_data.copy()\n",
    "            research_data_mapped['salary_text'] = research_data_mapped[salary_col].map(reverse_salary_map)\n",
    "            salary_counts = research_data_mapped['salary_text'].value_counts()\n",
    "        else:\n",
    "            salary_counts = research_data[salary_col].value_counts()\n",
    "        \n",
    "        # Reorder based on salary categories\n",
    "        salary_counts = salary_counts.reindex(salary_categories, fill_value=0)\n",
    "        \n",
    "        # Convert to proportions\n",
    "        salary_proportions = salary_counts / salary_counts.sum()\n",
    "        \n",
    "        all_proportions.append(salary_proportions.values)\n",
    "        research_names.append(research_labels.get(research_col, research_col.split('=')[1].replace(')', '')))\n",
    "        sample_sizes.append(len(research_data))\n",
    "    \n",
    "    if len(all_proportions) == 0:\n",
    "        print(\"No valid data found for any research type!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to numpy array for easier plotting\n",
    "    proportions_array = np.array(all_proportions).T  # Transpose so categories are rows, research types are columns\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "    \n",
    "    # Create stacked bars\n",
    "    bottom = np.zeros(len(research_names))\n",
    "    \n",
    "    for i, category in enumerate(salary_categories):\n",
    "        if i < len(proportions_array):\n",
    "            bars = ax.bar(research_names, proportions_array[i], \n",
    "                         bottom=bottom, label=category, color=pastel_rainbow[i])\n",
    "            bottom += proportions_array[i]\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_ylabel('Proportion', fontsize=12)\n",
    "    ax.set_xlabel('Research Type', fontsize=12)\n",
    "    ax.set_title('Salary Distribution by Research Type', fontsize=12, )\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add sample sizes to x-axis labels\n",
    "    x_labels_with_n = [f\"{name}\\n(n={n})\" for name, n in zip(research_names, sample_sizes)]\n",
    "    ax.set_xticklabels(x_labels_with_n)\n",
    "    \n",
    "    # Create legend (reversed to match stacking order from lowest to highest salary)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title='Salary Range', \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the combined plot for research type vs. salary\n",
    "fig, ax = create_combined_research_salary_plot(\n",
    "    data=df_scientist_melted,\n",
    "    salary_col='salary_ordinal'\n",
    ")\n",
    "\n",
    "if fig is not None:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS Salary Plots - Pairwise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for multiple interviews vs. salary\n",
    "fig, ax = create_stacked_bar_with_stats(\n",
    "    data=df_scientist_melted, \n",
    "    x_col='multiple_interviews',\n",
    "    y_col='salary_ordinal', \n",
    "    order=[True,False],\n",
    "    pairs=[(True,False)],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for extra degree vs. salary\n",
    "fig, ax = create_stacked_bar_with_stats(\n",
    "    data=df_scientist_melted, \n",
    "    x_col='extra_degree',\n",
    "    y_col='salary_ordinal', \n",
    "    order=[True,False],\n",
    "    pairs=[(True,False)],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for gender vs. salary\n",
    "fig, ax = create_stacked_bar_with_stats(\n",
    "    data=df_scientist_melted, \n",
    "    x_col='gender',\n",
    "    y_col='salary_ordinal', \n",
    "    order=['Man','Woman'],\n",
    "    pairs=[('Man','Woman')],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist_salary = df_scientist_melted[['internal_offer', 'salary_range_offered', 'salary_ordinal',\n",
    "                                           'multiple_interviews', 'extra_degree', 'gender',\n",
    "                                           'Do you identify as underrepresented in medicine?',]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS Startup Package Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist_melted['If yes, what is the approximate value of your startup package?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count plot for startup package values\n",
    "plt.figure(figsize=(8, 3))\n",
    "sns.countplot(data=df_scientist_melted, \n",
    "              y='If yes, what is the approximate value of your startup package?',\n",
    "              hue='Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?',\n",
    "              order=df_scientist_melted['If yes, what is the approximate value of your startup package?'].value_counts().index,\n",
    "              palette=pastel_rainbow)\n",
    "\n",
    "plt.title('Count of Startup Package Values by K08/K23 Grant Status')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Startup Package Value')\n",
    "plt.legend(title='K08/K23 Grant Already Awarded?', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ordered categories for startup packages\n",
    "startup_categories = [\n",
    "    'Under $250,000',\n",
    "    '$250,000-$499,999',\n",
    "    '$500,000-$1,000,000',\n",
    "    'Over $1,000,000'\n",
    "]\n",
    "\n",
    "# Convert to categorical with ordering\n",
    "df_scientist_melted['startup_range_offered'] = pd.Categorical(\n",
    "    df_scientist_melted['If yes, what is the approximate value of your startup package?'], \n",
    "    categories=startup_categories, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Create ordinal mapping for startup packages\n",
    "startup_map = {\n",
    "    'Under $250,000': 1,\n",
    "    '$250,000-$499,999': 2,\n",
    "    '$500,000-$1,000,000': 3,\n",
    "    'Over $1,000,000': 4\n",
    "}\n",
    "\n",
    "df_scientist_melted['startup_ordinal'] = df_scientist_melted['startup_range_offered'].map(startup_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_startup_proportion_plot(data, x_col, startup_col, order=None, pairs=None, \n",
    "                                 test='Mann-Whitney', loc='inside', \n",
    "                                 text_format='simple', figsize=(7, 4), xlabel=None, xticklabels=None, ax=None):\n",
    "    \n",
    "    # Prepare data - drop rows with missing values\n",
    "    df_plot = data[[x_col, startup_col, 'startup_ordinal']].dropna()\n",
    "    \n",
    "    # Create crosstab using the actual categorical column\n",
    "    crosstab = pd.crosstab(df_plot[x_col], df_plot[startup_col])\n",
    "    \n",
    "    # Reorder columns based on startup categories order\n",
    "    existing_categories = [cat for cat in startup_categories if cat in crosstab.columns]\n",
    "    crosstab = crosstab.reindex(columns=existing_categories, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Get sample sizes for each x category\n",
    "    sample_sizes = crosstab.sum(axis=1)\n",
    "    \n",
    "    # Option 5: Monochromatic Blues\n",
    "    crest_colors = sns.color_palette(\"crest\", n_colors=len(existing_categories))\n",
    "\n",
    "    # Create the stacked bar plot with proportions\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=crest_colors[:len(existing_categories)])\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_title('Distribution of Startup Package Ranges')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Fix legend order to match stacking order (flip it)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title='Startup Package Range', \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Add sample sizes under x-axis labels\n",
    "    x_labels_orig = ax.get_xticklabels()\n",
    "    \n",
    "    # Get the actual order of categories as they appear in the plot\n",
    "    actual_categories = crosstab_prop.index.tolist()\n",
    "    \n",
    "    for i, (label, category) in enumerate(zip(x_labels_orig, actual_categories)):\n",
    "        n = sample_sizes[category]  # Get sample size for this specific category\n",
    "        \n",
    "        if xticklabels:\n",
    "            # Find the matching custom label for this category\n",
    "            if order:\n",
    "                # If order is specified, use the position in the order list\n",
    "                try:\n",
    "                    category_index = order.index(category)\n",
    "                    current_text = xticklabels[category_index] if category_index < len(xticklabels) else category\n",
    "                except ValueError:\n",
    "                    current_text = category\n",
    "            else:\n",
    "                # If no order specified, use position in the plot\n",
    "                current_text = xticklabels[i] if i < len(xticklabels) else category\n",
    "        else:\n",
    "            # Use original category name\n",
    "            current_text = category\n",
    "            \n",
    "        new_text = f\"{current_text}\\n(n={n})\"\n",
    "        label.set_text(new_text)\n",
    "    \n",
    "    # Set the updated labels\n",
    "    ax.set_xticklabels(x_labels_orig)\n",
    "    \n",
    "    # Set x-axis label if provided\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    \n",
    "    # Add statistical annotation if pairs are provided\n",
    "    if pairs:\n",
    "        annotator = Annotator(ax, pairs, data=df_plot, x=x_col, y='startup_ordinal', order=order)\n",
    "        annotator.configure(test=test, loc=loc, text_format=text_format)\n",
    "        annotator.apply_and_annotate()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for K08/K23 grant status vs. startup package\n",
    "fig, ax = create_startup_proportion_plot(\n",
    "    data=df_scientist_melted,\n",
    "    x_col='Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?',\n",
    "    startup_col='If yes, what is the approximate value of your startup package?',\n",
    "    order=['Yes', 'No'],\n",
    "    pairs=[('Yes', 'No')],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    figsize=(7, 4),\n",
    "    xlabel='K08/K23 already?'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist_melted = df_scientist_melted.rename(columns={\n",
    "    'Did the startup package have salary cost-sharing? (e.g., your grant does not cover all your salary and hence you need to pay the differential via your startup funds)': 'cost_sharing'\n",
    "})\n",
    "fig, ax = create_startup_proportion_plot(\n",
    "    data=df_scientist_melted.loc[df_scientist_melted['cost_sharing'] != 'Not sure'],\n",
    "    x_col='cost_sharing',\n",
    "    startup_col='If yes, what is the approximate value of your startup package?',\n",
    "    order = ['Yes','No'],\n",
    "    pairs = [('Yes','No')],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    figsize=(7, 4),\n",
    "    xlabel='Salary cost-sharing in startup package?',\n",
    "    xticklabels=['Yes', 'No']\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_startup_proportion_plot(\n",
    "    data=df_scientist_melted,\n",
    "    x_col='gender',\n",
    "    startup_col='If yes, what is the approximate value of your startup package?',\n",
    "    order=['Man', 'Woman'],\n",
    "    pairs=[('Man', 'Woman')],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    figsize=(7, 4),\n",
    "    xlabel='Gender',\n",
    "    xticklabels=['Man', 'Woman']\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_startup_proportion_plot(\n",
    "    data=df_scientist_melted,\n",
    "    x_col='extra_degree',\n",
    "    startup_col='If yes, what is the approximate value of your startup package?',\n",
    "    order = [True,False],\n",
    "    pairs = [(True,False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    figsize=(7, 4),\n",
    "    xlabel='Additional Degree?',\n",
    "    xticklabels=['Yes', 'No']\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_startup_proportion_plot(\n",
    "    data=df_scientist_melted,\n",
    "    x_col='internal_offer',\n",
    "    startup_col='If yes, what is the approximate value of your startup package?',\n",
    "    order = [True,False],\n",
    "    pairs = [(True,False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    figsize=(7, 4),\n",
    "    xlabel='Internal offer?',\n",
    "    xticklabels=['Yes', 'No']\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_startup_proportion_plot(\n",
    "    data=df_scientist_melted,\n",
    "    x_col='multiple_interviews',\n",
    "    startup_col='If yes, what is the approximate value of your startup package?',\n",
    "    order = [True,False],\n",
    "    pairs = [(True,False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    figsize=(7, 4),\n",
    "    xlabel='Multiple interviews?',\n",
    "    xticklabels=['Yes', 'No']\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS Figure - Combined Startup Package Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined figure with 2x2 subplot layout\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "plt.subplots_adjust(hspace=0.4)  # Add more vertical spacing between rows\n",
    "\n",
    "# Set global font sizes for better readability on printed page\n",
    "plt.rcParams.update({'font.size': 16})  # Base font size\n",
    "\n",
    "# Rename cost-sharing column (if not already renamed)\n",
    "df_scientist_melted = df_scientist_melted.rename(columns={\n",
    "    'Did the startup package have salary cost-sharing? (e.g., your grant does not cover all your salary and hence you need to pay the differential via your startup funds)': 'cost_sharing'\n",
    "})\n",
    "\n",
    "# Define colors once for consistency across all subplots\n",
    "crest_colors = sns.color_palette(\"crest\", n_colors=len(startup_categories))\n",
    "\n",
    "# A) K prior to negotiation comparison\n",
    "ax_a = axes[0, 0]\n",
    "df_plot_a = df_scientist_melted[['Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?', \n",
    "                                'If yes, what is the approximate value of your startup package?', 'startup_ordinal']].dropna()\n",
    "crosstab_a = pd.crosstab(df_plot_a['Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?'], \n",
    "                        df_plot_a['If yes, what is the approximate value of your startup package?'])\n",
    "existing_categories_a = [cat for cat in startup_categories if cat in crosstab_a.columns]\n",
    "crosstab_a = crosstab_a.reindex(columns=existing_categories_a, fill_value=0)\n",
    "crosstab_prop_a = crosstab_a.div(crosstab_a.sum(axis=1), axis=0)\n",
    "sample_sizes_a = crosstab_a.sum(axis=1)\n",
    "\n",
    "crosstab_prop_a.plot(kind='bar', stacked=True, ax=ax_a, color=crest_colors[:len(existing_categories_a)], legend=False)\n",
    "ax_a.set_ylabel('Proportion', fontsize=18)\n",
    "ax_a.set_title('K08/K23 Prior to Negotiation', fontsize=20)\n",
    "ax_a.text(-0.12, 1.05, 'A)', transform=ax_a.transAxes, fontsize=24, fontweight='bold')\n",
    "ax_a.set_ylim(0, 1)\n",
    "ax_a.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "ax_a.tick_params(axis='y', labelsize=16)\n",
    "ax_a.set_xlabel('')  # Set blank x-label\n",
    "\n",
    "# Add sample sizes and custom labels\n",
    "x_labels_a = ['Yes', 'No']\n",
    "actual_categories_a = crosstab_prop_a.index.tolist()\n",
    "# Map actual categories to custom labels\n",
    "label_mapping_a = dict(zip(['Yes', 'No'], x_labels_a))\n",
    "tick_labels_a = [label_mapping_a.get(cat, cat) for cat in actual_categories_a]\n",
    "\n",
    "for i, category in enumerate(actual_categories_a):\n",
    "    n = sample_sizes_a[category]\n",
    "    custom_label = label_mapping_a.get(category, category)\n",
    "    ax_a.text(i, -0.05, f\"{custom_label}\\n(n={n})\", ha='center', va='top', transform=ax_a.transData, fontsize=15)\n",
    "\n",
    "ax_a.set_xticklabels(['', ''])  # Clear tick labels since we're using text annotations\n",
    "ax_a.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "\n",
    "# Add statistical annotation\n",
    "annotator_a = Annotator(ax_a, [('Yes', 'No')], data=df_plot_a, \n",
    "                       x='Had you already been awarded a K08/K23 or equivalent grant prior to beginning job negotiations?', \n",
    "                       y='startup_ordinal', order=['Yes', 'No'])\n",
    "annotator_a.configure(test='Mann-Whitney', loc='inside', text_format='simple')\n",
    "annotator_a.apply_and_annotate()\n",
    "\n",
    "# B) Cost-sharing\n",
    "ax_b = axes[0, 1]\n",
    "df_plot_b = df_scientist_melted.loc[df_scientist_melted['cost_sharing'] != 'Not sure']\n",
    "df_plot_b = df_plot_b[['cost_sharing', 'If yes, what is the approximate value of your startup package?', 'startup_ordinal']].dropna()\n",
    "crosstab_b = pd.crosstab(df_plot_b['cost_sharing'], df_plot_b['If yes, what is the approximate value of your startup package?'])\n",
    "existing_categories_b = [cat for cat in startup_categories if cat in crosstab_b.columns]\n",
    "crosstab_b = crosstab_b.reindex(columns=existing_categories_b, fill_value=0)\n",
    "crosstab_prop_b = crosstab_b.div(crosstab_b.sum(axis=1), axis=0)\n",
    "sample_sizes_b = crosstab_b.sum(axis=1)\n",
    "\n",
    "crosstab_prop_b.plot(kind='bar', stacked=True, ax=ax_b, color=crest_colors[:len(existing_categories_b)], legend=False)\n",
    "ax_b.set_ylabel('Proportion', fontsize=18)\n",
    "ax_b.set_title('Salary Cost-sharing', fontsize=20)\n",
    "ax_b.text(-0.12, 1.05, 'B)', transform=ax_b.transAxes, fontsize=24, fontweight='bold')\n",
    "ax_b.set_ylim(0, 1)\n",
    "ax_b.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "ax_b.tick_params(axis='y', labelsize=16)\n",
    "ax_b.set_xlabel('')  # Set blank x-label\n",
    "\n",
    "# Add sample sizes and custom labels\n",
    "x_labels_b = ['Yes', 'No']\n",
    "actual_categories_b = crosstab_prop_b.index.tolist()\n",
    "# Map actual categories to custom labels\n",
    "label_mapping_b = dict(zip(['Yes', 'No'], x_labels_b))\n",
    "tick_labels_b = [label_mapping_b.get(cat, cat) for cat in actual_categories_b]\n",
    "\n",
    "for i, category in enumerate(actual_categories_b):\n",
    "    n = sample_sizes_b[category]\n",
    "    custom_label = label_mapping_b.get(category, category)\n",
    "    ax_b.text(i, -0.05, f\"{custom_label}\\n(n={n})\", ha='center', va='top', transform=ax_b.transData, fontsize=15)\n",
    "\n",
    "ax_b.set_xticklabels(['', ''])  # Clear tick labels since we're using text annotations\n",
    "ax_b.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "\n",
    "# Add statistical annotation\n",
    "annotator_b = Annotator(ax_b, [('Yes', 'No')], data=df_plot_b, x='cost_sharing', y='startup_ordinal', order=['Yes', 'No'])\n",
    "annotator_b.configure(test='Mann-Whitney', loc='inside', text_format='simple')\n",
    "annotator_b.apply_and_annotate()\n",
    "\n",
    "# C) Gender\n",
    "ax_c = axes[1, 0]\n",
    "df_plot_c = df_scientist_melted[['gender', 'If yes, what is the approximate value of your startup package?', 'startup_ordinal']].dropna()\n",
    "crosstab_c = pd.crosstab(df_plot_c['gender'], df_plot_c['If yes, what is the approximate value of your startup package?'])\n",
    "existing_categories_c = [cat for cat in startup_categories if cat in crosstab_c.columns]\n",
    "crosstab_c = crosstab_c.reindex(columns=existing_categories_c, fill_value=0)\n",
    "crosstab_prop_c = crosstab_c.div(crosstab_c.sum(axis=1), axis=0)\n",
    "sample_sizes_c = crosstab_c.sum(axis=1)\n",
    "\n",
    "crosstab_prop_c.plot(kind='bar', stacked=True, ax=ax_c, color=crest_colors[:len(existing_categories_c)], legend=False)\n",
    "ax_c.set_ylabel('Proportion', fontsize=18)\n",
    "ax_c.set_title('Gender Comparison', fontsize=20)\n",
    "ax_c.text(-0.12, 1.05, 'C)', transform=ax_c.transAxes, fontsize=24, fontweight='bold')\n",
    "ax_c.set_ylim(0, 1)\n",
    "ax_c.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "ax_c.tick_params(axis='y', labelsize=16)\n",
    "ax_c.set_xlabel('')  # Set blank x-label\n",
    "\n",
    "# Add sample sizes and custom labels\n",
    "x_labels_c = ['Man', 'Woman']\n",
    "actual_categories_c = crosstab_prop_c.index.tolist()\n",
    "# Map actual categories to custom labels\n",
    "label_mapping_c = dict(zip(['Man', 'Woman'], x_labels_c))\n",
    "tick_labels_c = [label_mapping_c.get(cat, cat) for cat in actual_categories_c]\n",
    "\n",
    "for i, category in enumerate(actual_categories_c):\n",
    "    n = sample_sizes_c[category]\n",
    "    custom_label = label_mapping_c.get(category, category)\n",
    "    ax_c.text(i, -0.05, f\"{custom_label}\\n(n={n})\", ha='center', va='top', transform=ax_c.transData, fontsize=15)\n",
    "\n",
    "ax_c.set_xticklabels(['', ''])  # Clear tick labels since we're using text annotations\n",
    "ax_c.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "\n",
    "# Add statistical annotation\n",
    "annotator_c = Annotator(ax_c, [('Man', 'Woman')], data=df_plot_c, x='gender', y='startup_ordinal', order=['Man', 'Woman'])\n",
    "annotator_c.configure(test='Mann-Whitney', loc='inside', text_format='simple')\n",
    "annotator_c.apply_and_annotate()\n",
    "\n",
    "# D) Multiple Interviews\n",
    "ax_d = axes[1, 1]\n",
    "df_plot_d = df_scientist_melted[['multiple_interviews', 'If yes, what is the approximate value of your startup package?', 'startup_ordinal']].dropna()\n",
    "crosstab_d = pd.crosstab(df_plot_d['multiple_interviews'], df_plot_d['If yes, what is the approximate value of your startup package?'])\n",
    "existing_categories_d = [cat for cat in startup_categories if cat in crosstab_d.columns]\n",
    "crosstab_d = crosstab_d.reindex(columns=existing_categories_d, fill_value=0)\n",
    "crosstab_prop_d = crosstab_d.div(crosstab_d.sum(axis=1), axis=0)\n",
    "sample_sizes_d = crosstab_d.sum(axis=1)\n",
    "\n",
    "crosstab_prop_d.plot(kind='bar', stacked=True, ax=ax_d, color=crest_colors[:len(existing_categories_d)])\n",
    "ax_d.set_ylabel('Proportion', fontsize=18)\n",
    "ax_d.set_title('Multiple Interviews', fontsize=20)\n",
    "ax_d.text(-0.12, 1.05, 'D)', transform=ax_d.transAxes, fontsize=24, fontweight='bold')\n",
    "ax_d.set_ylim(0, 1)\n",
    "ax_d.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "ax_d.tick_params(axis='y', labelsize=16)\n",
    "ax_d.set_xlabel('')  # Set blank x-label\n",
    "\n",
    "# Add sample sizes and custom labels\n",
    "x_labels_d = ['Yes', 'No'] # Assuming True/False maps to Yes/No\n",
    "actual_categories_d = crosstab_prop_d.index.tolist()\n",
    "# Map actual categories to custom labels\n",
    "label_mapping_d = dict(zip([True, False], x_labels_d))\n",
    "tick_labels_d = [label_mapping_d.get(cat, str(cat)) for cat in actual_categories_d]\n",
    "\n",
    "for i, category in enumerate(actual_categories_d):\n",
    "    n = sample_sizes_d[category]\n",
    "    custom_label = label_mapping_d.get(category, str(category))\n",
    "    ax_d.text(i, -0.05, f\"{custom_label}\\n(n={n})\", ha='center', va='top', transform=ax_d.transData, fontsize=15)\n",
    "\n",
    "ax_d.set_xticklabels(['', ''])  # Clear tick labels since we're using text annotations\n",
    "ax_d.tick_params(axis='x', rotation=0, top=False, bottom=True, labeltop=False, labelbottom=True, labelsize=16)\n",
    "\n",
    "# Add statistical annotation\n",
    "annotator_d = Annotator(ax_d, [(True, False)], data=df_plot_d, x='multiple_interviews', y='startup_ordinal', order=[True, False])\n",
    "annotator_d.configure(test='Mann-Whitney', loc='inside', text_format='simple')\n",
    "annotator_d.apply_and_annotate()\n",
    "\n",
    "# Get legend from the last subplot and place it outside the figure\n",
    "handles, labels = ax_d.get_legend_handles_labels()\n",
    "fig.legend(reversed(handles), reversed(labels), title='Startup Package Range', \n",
    "          bbox_to_anchor=(1.02, 0.5), loc='center left', fontsize=16, title_fontsize=18)\n",
    "\n",
    "# Remove the legend from subplot D\n",
    "ax_d.get_legend().remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.95)  # Make room for the legend\n",
    "plt.savefig('fig_startup_package_analysis.pdf', format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS Research Type vs. Startup Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_type_columns = [\n",
    "    'Type of Research (select all that apply) (choice=Basic)',\n",
    "    'Type of Research (select all that apply) (choice=Translational)', \n",
    "    'Type of Research (select all that apply) (choice=Clinical)',\n",
    "    'Type of Research (select all that apply) (choice=Computational (only dry lab))'\n",
    "]\n",
    "\n",
    "# Shorter labels for plotting\n",
    "research_labels = {\n",
    "    'Type of Research (select all that apply) (choice=Basic)': 'Basic\\nResearch',\n",
    "    'Type of Research (select all that apply) (choice=Translational)': 'Translational\\nResearch',\n",
    "    'Type of Research (select all that apply) (choice=Clinical)': 'Clinical\\nResearch',\n",
    "    'Type of Research (select all that apply) (choice=Computational (only dry lab))': 'Computational\\nResearch'\n",
    "}\n",
    "\n",
    "# Define startup package categories in order\n",
    "startup_categories = [\n",
    "    'Under $250,000',\n",
    "    '$250,000-$499,999',\n",
    "    '$500,000-$1,000,000',\n",
    "    'Over $1,000,000'\n",
    "]\n",
    "\n",
    "def create_combined_research_startup_plot(data, startup_col):\n",
    "    \"\"\"Create a single plot with stacked bars for each research type showing startup package distribution\"\"\"\n",
    "    \n",
    "    # Check which columns actually exist\n",
    "    existing_research_cols = [col for col in research_type_columns if col in data.columns]\n",
    "    print(f\"Found {len(existing_research_cols)} research type columns in data\")\n",
    "    \n",
    "    if len(existing_research_cols) == 0:\n",
    "        print(\"No research type columns found!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Prepare data for all research types\n",
    "    all_proportions = []\n",
    "    research_names = []\n",
    "    sample_sizes = []\n",
    "    \n",
    "    for research_col in existing_research_cols:\n",
    "        # Filter data for this research type where value is 'Checked'\n",
    "        try:\n",
    "            research_mask = data[research_col] == 'Checked'\n",
    "            research_data = data[research_mask].copy()\n",
    "        except Exception as e:\n",
    "            print(f\"Error filtering {research_col}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if len(research_data) == 0:\n",
    "            print(f\"No data for {research_col}\")\n",
    "            continue\n",
    "        \n",
    "        # Create value counts for startup packages\n",
    "        startup_counts = research_data[startup_col].value_counts()\n",
    "        \n",
    "        # Reorder based on startup categories\n",
    "        existing_categories = [cat for cat in startup_categories if cat in startup_counts.index]\n",
    "        startup_counts = startup_counts.reindex(startup_categories, fill_value=0)\n",
    "        \n",
    "        # Convert to proportions\n",
    "        startup_proportions = startup_counts / startup_counts.sum()\n",
    "        \n",
    "        all_proportions.append(startup_proportions.values)\n",
    "        research_names.append(research_labels.get(research_col, research_col.split('=')[1].replace(')', '')))\n",
    "        sample_sizes.append(len(research_data))\n",
    "    \n",
    "    if len(all_proportions) == 0:\n",
    "        print(\"No valid data found for any research type!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to numpy array for easier plotting\n",
    "    proportions_array = np.array(all_proportions).T  # Transpose so categories are rows, research types are columns\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    # Get colors\n",
    "    crest_colors = sns.color_palette(\"crest\", n_colors=len(startup_categories))\n",
    "    \n",
    "    # Create stacked bars\n",
    "    bottom = np.zeros(len(research_names))\n",
    "    \n",
    "    for i, category in enumerate(startup_categories):\n",
    "        if i < len(proportions_array):\n",
    "            bars = ax.bar(research_names, proportions_array[i], \n",
    "                         bottom=bottom, label=category, color=crest_colors[i])\n",
    "            bottom += proportions_array[i]\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_ylabel('Proportion', fontsize=12)\n",
    "    ax.set_xlabel('Research Type', fontsize=12)\n",
    "    ax.set_title('Startup Package Distribution by Research Type', fontsize=12, )\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add sample sizes to x-axis labels\n",
    "    x_labels_with_n = [f\"{name}\\n(n={n})\" for name, n in zip(research_names, sample_sizes)]\n",
    "    ax.set_xticklabels(x_labels_with_n)\n",
    "    \n",
    "    # Create legend (reversed to match stacking order)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title='Startup Package Range', \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the combined plot for research type vs. startup package\n",
    "fig, ax = create_combined_research_startup_plot(\n",
    "    data=df_scientist_melted,\n",
    "    startup_col='If yes, what is the approximate value of your startup package?'\n",
    ")\n",
    "\n",
    "if fig is not None:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of Startup vs. Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startup_order = [\n",
    "    'Under $250,000',\n",
    "    '$250,000-$499,999', \n",
    "    '$500,000-$1,000,000',\n",
    "    'Over $1,000,000'\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Filter out None values from startup package before creating crosstab\n",
    "df_filtered = df_scientist_melted[\n",
    "    df_scientist_melted['If yes, what is the approximate value of your startup package?'] != 'None'\n",
    "]\n",
    "\n",
    "# Create custom mako colormap that doesn't start with black\n",
    "from matplotlib.colors import ListedColormap\n",
    "mako_cmap = sns.color_palette(\"mako\", as_cmap=True)\n",
    "# Create a truncated version that starts from a lighter color (skip the darkest 20%)\n",
    "mako_colors = mako_cmap(np.linspace(0.2, 1.0, 256))\n",
    "custom_mako = ListedColormap(mako_colors)\n",
    "\n",
    "# Create crosstab and reindex with proper startup package order\n",
    "crosstab_data = pd.crosstab(\n",
    "    df_filtered['If yes, what is the approximate value of your startup package?'],\n",
    "    df_filtered['salary_range_offered']\n",
    ").dropna()\n",
    "\n",
    "# Reindex to ensure proper ordering of startup packages\n",
    "crosstab_data = crosstab_data.reindex(startup_order, fill_value=0)\n",
    "\n",
    "# Create the heatmap with prettier styling\n",
    "sns.heatmap(\n",
    "    crosstab_data,\n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap=custom_mako,  \n",
    "    linecolor='white',\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Number of Responses'},\n",
    "    square=False,\n",
    "    annot_kws={'fontsize': 10, 'fontweight': 'bold'}\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Startup Package vs Salary Range Distribution', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Salary Range', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Startup Package Value', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=35, ha='right', fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig_ps_heatmap.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE Job Offer Melting and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_job_offers_ce(df):\n",
    "    \"\"\"\n",
    "    Melt a wide dataframe with multiple job offers into long format\n",
    "    where each row represents one job offer with demographics for Clinician Educators.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define demographic columns (constant across all job offers)\n",
    "    demographic_cols = [\n",
    "        \"Do you agree to participate in this survey? By clicking 'I Agree', you are consenting to participate in this survey. \",\n",
    "        'Degrees Held (Select all that apply) (choice=MD, DO, MBBS or equivalent)',\n",
    "        'Degrees Held (Select all that apply) (choice=MS (including MSCE, MSCI, MSci, MPH, etc.))',\n",
    "        'Degrees Held (Select all that apply) (choice=PhD)',\n",
    "        'Degrees Held (Select all that apply) (choice=Other)',\n",
    "        'If Other for Degrees Held, please specify:',\n",
    "        'Did you accept a job at the same institution where you completed fellowship training?',\n",
    "        'Gender',\n",
    "        'If you prefer to self-describe your gender: ',\n",
    "        'Race/Ethnicity (Select all that apply) (choice=Asian or Asian American)',\n",
    "        'Race/Ethnicity (Select all that apply) (choice=Black or African American)',\n",
    "        'Race/Ethnicity (Select all that apply) (choice=Hispanic, Latino, Latina, or LatinX)',\n",
    "        'Race/Ethnicity (Select all that apply) (choice=White)',\n",
    "        'Race/Ethnicity (Select all that apply) (choice=Other)',\n",
    "        'Race/Ethnicity (Select all that apply) (choice=Prefer not to answer)',\n",
    "        'Do you identify as underrepresented in medicine?',\n",
    "        'Type of Job Most Recently Accepted',\n",
    "         'multiple_interviews',\n",
    "         'extra_degree',\n",
    "         'gender'\n",
    "    ]\n",
    "    \n",
    "    # Define job offer columns without free text responses\n",
    "    job_offer_base_cols = [\n",
    "        'What geographic region is the institution?',\n",
    "        'Did you interview at and receive offers from multiple institutions?',\n",
    "        'Cost of living at institution of job negotiation',\n",
    "        'What salary range were you offered?',\n",
    "        'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?',\n",
    "        'In your most recently accepted offer, what is your percent clinical time?',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=CME role)',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=Clinical program building)',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=Quality improvement)',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)',\n",
    "        'What is the non-clinical full-time equivalent for? (choice=Other)',\n",
    "        'Did you receive non-clinical FTE?',\n",
    "        'Do you have additional FTE dedicated for research?',\n",
    "        \"Does a designation of 'core faculty' within residency or fellowship training programs get allocated FTE at this institution?\\xa0\",\n",
    "        'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?',\n",
    "        'Is there transparency about how salary equity is evaluated at this institution?',\n",
    "        'Were any signing bonuses or performance-based incentives part of your negotiation?',\n",
    "        'Value of bonuses/incentives',\n",
    "        'Were you offered a relocation package?',\n",
    "        'If yes, what was the total value of the relocation package?',\n",
    "        'Do you have a noncompete clause?',\n",
    "        'Why did you choose to accept this job over other offers?'\n",
    "    ]\n",
    "    \n",
    "    # Create mappings for each job offer\n",
    "    job_offer_mappings = {\n",
    "        'job_offer_1': {\n",
    "            'What geographic region is the institution?': 'What geographic region is the institution?.3',\n",
    "            'Did you interview at and receive offers from multiple institutions?': 'Did you interview at and receive offers from multiple institutions?.1',\n",
    "            'Cost of living at institution of job negotiation': 'Cost of living at institution of job negotiation',\n",
    "            'What salary range were you offered?': 'What salary range were you offered?.3',\n",
    "            'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?': 'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?',\n",
    "            'In your most recently accepted offer, what is your percent clinical time?': 'In your most recently accepted offer, what is your percent clinical time?',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))': 'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))': 'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=CME role)': 'What is the non-clinical full-time equivalent for? (choice=CME role)',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)': 'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Clinical program building)': 'What is the non-clinical full-time equivalent for? (choice=Clinical program building)',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Quality improvement)': 'What is the non-clinical full-time equivalent for? (choice=Quality improvement)',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)': 'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Other)': 'What is the non-clinical full-time equivalent for? (choice=Other)',\n",
    "            'Did you receive non-clinical FTE?': 'Did you receive non-clinical FTE?',\n",
    "            'Do you have additional FTE dedicated for research?': 'Do you have additional FTE dedicated for research?',\n",
    "            \"Does a designation of 'core faculty' within residency or fellowship training programs get allocated FTE at this institution?\\xa0\": \"Does a designation of 'core faculty' within residency or fellowship training programs get allocated FTE at this institution?\\xa0\",\n",
    "            'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?': 'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?',\n",
    "            'Is there transparency about how salary equity is evaluated at this institution?': 'Is there transparency about how salary equity is evaluated at this institution?',\n",
    "            'Were any signing bonuses or performance-based incentives part of your negotiation?': 'Were any signing bonuses or performance-based incentives part of your negotiation?.3',\n",
    "            'Value of bonuses/incentives': 'Value of bonuses/incentives',\n",
    "            'Were you offered a relocation package?': 'Were you offered a relocation package?.3',\n",
    "            'If yes, what was the total value of the relocation package?': 'If yes, what was the total value of the relocation package?.3',\n",
    "            'Do you have a noncompete clause?': 'Do you have a noncompete clause?.3',\n",
    "            'Why did you choose to accept this job over other offers?': 'Why did you choose to accept this job over other offers?.1'\n",
    "        },\n",
    "        'job_offer_2': {\n",
    "            'Cost of living at institution of job negotiation': 'Cost of living at institution of job negotiation.1',\n",
    "            'What salary range were you offered?': 'What salary range were you offered?.4',\n",
    "            'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?': 'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?.1',\n",
    "            'In your most recently accepted offer, what is your percent clinical time?': 'In your most recently accepted offer, what is your percent clinical time?.1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))': 'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director)).1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))': 'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director)).1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=CME role)': 'What is the non-clinical full-time equivalent for? (choice=CME role).1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)': 'What is the non-clinical full-time equivalent for? (choice=Other medical educator role).1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Clinical program building)': 'What is the non-clinical full-time equivalent for? (choice=Clinical program building).1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Quality improvement)': 'What is the non-clinical full-time equivalent for? (choice=Quality improvement).1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)': 'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties).1',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Other)': 'What is the non-clinical full-time equivalent for? (choice=Other).1',\n",
    "            'Did you receive non-clinical FTE?': 'Did you receive non-clinical FTE?.1',\n",
    "            'Do you have additional FTE dedicated for research?': 'Do you have additional FTE dedicated for research?.1',\n",
    "            \"Does a designation of 'core faculty' within residency or fellowship training programs get allocated FTE at this institution?\\xa0\": \"Does a designation of 'core faculty' within residency or fellowship training programs get allocated FTE at this institution?\\xa0.1\",\n",
    "            'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?': 'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?.1',\n",
    "            'Is there transparency about how salary equity is evaluated at this institution?': 'Is there transparency about how salary equity is evaluated at this institution?.1',\n",
    "            'Were any signing bonuses or performance-based incentives part of your negotiation?': 'Were any signing bonuses or performance-based incentives part of your negotiation?.4',\n",
    "            'Value of bonuses/incentives': 'Value of bonuses/incentives.1',\n",
    "            'Were you offered a relocation package?': 'Were you offered a relocation package?.4',\n",
    "            'If yes, what was the total value of the relocation package?': 'If yes, what was the total value of the relocation package?.4',\n",
    "            'Do you have a noncompete clause?': 'Do you have a noncompete clause?.4',\n",
    "            'Did you interview at and receive offers from yet another institution?': 'Did you interview at and receive offers from yet another institution?.1'\n",
    "        },\n",
    "        'job_offer_3': {\n",
    "            'Cost of living at institution of job negotiation': 'Cost of living at institution of job negotiation.2',\n",
    "            'What salary range were you offered?': 'What salary range were you offered?.5',\n",
    "            'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?': 'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?.2',\n",
    "            'In your most recently accepted offer, what is your percent clinical time?': 'In your most recently accepted offer, what is your percent clinical time?.2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))': 'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director)).2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))': 'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director)).2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=CME role)': 'What is the non-clinical full-time equivalent for? (choice=CME role).2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)': 'What is the non-clinical full-time equivalent for? (choice=Other medical educator role).2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Clinical program building)': 'What is the non-clinical full-time equivalent for? (choice=Clinical program building).2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Quality improvement)': 'What is the non-clinical full-time equivalent for? (choice=Quality improvement).2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)': 'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties).2',\n",
    "            'What is the non-clinical full-time equivalent for? (choice=Other)': 'What is the non-clinical full-time equivalent for? (choice=Other).2',\n",
    "            'Did you receive non-clinical FTE?': 'Did you receive non-clinical FTE?.2',\n",
    "            'Do you have additional FTE dedicated for research?': 'Do you have additional FTE dedicated for research?.2',\n",
    "            \"Does a designation of 'core faculty' within residency or fellowship training programs get allocated FTE at this institution?\\xa0\": \"Does a designation of 'core faculty' within residency or fellowship training programs get allocated FTE at this institution?\\xa0.2\",\n",
    "            'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?': 'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?.2',\n",
    "            'Is there transparency about how salary equity is evaluated at this institution?': 'Is there transparency about how salary equity is evaluated at this institution?.2',\n",
    "            'Were any signing bonuses or performance-based incentives part of your negotiation?': 'Were any signing bonuses or performance-based incentives part of your negotiation?.5',\n",
    "            'Value of bonuses/incentives': 'Value of bonuses/incentives.2',\n",
    "            'Were you offered a relocation package?': 'Were you offered a relocation package?.5',\n",
    "            'If yes, what was the total value of the relocation package?': 'If yes, what was the total value of the relocation package?.5',\n",
    "            'Do you have a noncompete clause?': 'Do you have a noncompete clause?.5',\n",
    "            'Did you interview at and receive offers from yet another institution? (You will not be asked to complete another set of questions.)': 'Did you interview at and receive offers from yet another institution? (You will not be asked to complete another set of questions.).1'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create list to store melted dataframes\n",
    "    melted_dfs = []\n",
    "    \n",
    "    # Create respondent ID if not exists\n",
    "    if 'respondent_id' not in df.columns:\n",
    "        df = df.reset_index()\n",
    "        df['respondent_id'] = df.index\n",
    "    \n",
    "    # Filter demographic columns to only include those that exist in the dataframe\n",
    "    existing_demographic_cols = [col for col in demographic_cols if col in df.columns]\n",
    "    \n",
    "    # Process each job offer\n",
    "    for job_offer_name, column_mapping in job_offer_mappings.items():\n",
    "        # Get columns that actually exist in the dataframe\n",
    "        existing_columns = {k: v for k, v in column_mapping.items() if v in df.columns}\n",
    "        \n",
    "        if not existing_columns:\n",
    "            continue\n",
    "            \n",
    "        # Create a dataframe for this job offer\n",
    "        job_df = df[existing_demographic_cols + ['respondent_id']].copy()\n",
    "        \n",
    "        # Add job offer identifier\n",
    "        job_df['job_offer_number'] = job_offer_name\n",
    "        \n",
    "        # Map the job offer columns\n",
    "        for standard_col, actual_col in existing_columns.items():\n",
    "            job_df[standard_col] = df[actual_col]\n",
    "        \n",
    "        # Remove rows where all job offer columns are null\n",
    "        job_offer_cols = list(existing_columns.keys())\n",
    "        job_df = job_df.dropna(subset=job_offer_cols, how='all')\n",
    "        \n",
    "        melted_dfs.append(job_df)\n",
    "    \n",
    "    # Combine all job offers\n",
    "    if melted_dfs:\n",
    "        final_df = pd.concat(melted_dfs, ignore_index=True)\n",
    "        \n",
    "        # Reorder columns for better readability\n",
    "        cols_order = ['respondent_id', 'job_offer_number'] + existing_demographic_cols + job_offer_base_cols\n",
    "        # Only include columns that exist in the dataframe\n",
    "        cols_order = [col for col in cols_order if col in final_df.columns]\n",
    "        final_df = final_df[cols_order]\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage:\n",
    "df_educator_melted = melt_job_offers_ce(df_educator)\n",
    "print(f\"Original shape: {df_educator.shape}\")\n",
    "print(f\"Melted shape: {df_educator_melted.shape}\")\n",
    "print(f\"Number of unique respondents: {df_educator_melted['respondent_id'].nunique()}\")\n",
    "print(f\"Job offers per respondent: {df_educator_melted.groupby('respondent_id')['job_offer_number'].count().describe()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_educator_melted['internal_offer'] = ((df_educator_melted['Did you accept a job at the same institution where you completed fellowship training?'] == 'Yes') & \n",
    "                              (df_educator_melted['job_offer_number'] == 'job_offer_1')).apply(lambda x: True if x else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_educator_melted['internal_offer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_educator_melted.to_csv('df_educator_melted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_cost_of_living(df):\n",
    "    col = 'Cost of living at institution of job negotiation'\n",
    "    # Remove rows where value is None, NaN, or empty string\n",
    "    return df[df[col].notnull() & (df[col] != '')]\n",
    "df_educator_melted = drop_empty_cost_of_living(df_educator_melted)\n",
    "df_educator_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_educator_melted.groupby('respondent_id')['job_offer_number'].count().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE Job Offers TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ 'What geographic region is the institution?',\n",
    "       'Cost of living at institution of job negotiation',\n",
    "       'What salary range were you offered?',\n",
    "       'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?',\n",
    "       'In your most recently accepted offer, what is your percent clinical time?',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))', \n",
    "      #  'What is the non-clinical full-time equivalent for? (choice=CME role)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Clinical program building)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Quality improvement)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Other)',\n",
    "       'Did you receive non-clinical FTE?',\n",
    "       'Do you have additional FTE dedicated for research?',\n",
    "          'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?',\n",
    "       'Is there transparency about how salary equity is evaluated at this institution?',\n",
    "       'Were any signing bonuses or performance-based incentives part of your negotiation?',\n",
    "       'Value of bonuses/incentives', 'Were you offered a relocation package?',\n",
    "       'If yes, what was the total value of the relocation package?',\n",
    "       'Do you have a noncompete clause?',]\n",
    "\n",
    "\n",
    "\n",
    "# Generate TableOne\n",
    "table1 = TableOne(df_educator_melted, columns=columns, categorical=columns,  rename=None, groupby='gender', pval=True)\n",
    "table1.to_csv('table1_job_offers_educator_byGender.csv')\n",
    "# table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE Clinical Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_categories = [\n",
    "    \"Less than 50%\",\n",
    "    \"50%\",\n",
    "    \"50-75%\",\n",
    "    \"75-89%\",\n",
    "    \"90-99%\",\n",
    "    \"100%\"\n",
    "]\n",
    "\n",
    "# Convert the column to a categorical type with the specified order\n",
    "df_educator_melted['percent_clinical_ordered'] = pd.Categorical(\n",
    "    df_educator_melted['In your most recently accepted offer, what is your percent clinical time?'],\n",
    "    categories=ordered_categories,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "flare_colors = sns.color_palette(\"flare\", n_colors=len(ordered_categories))\n",
    "counts = df_educator_melted['percent_clinical_ordered'].value_counts()\n",
    "counts = counts.reindex(ordered_categories)\n",
    "counts.plot(kind='barh', ax=ax, color=flare_colors, edgecolor='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('%FTE Clinical Time', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_categories = [\n",
    "    \"Less than 50%\",\n",
    "    \"50%\",\n",
    "    \"50-75%\",\n",
    "    \"75-89%\",\n",
    "    \"90-99%\",\n",
    "    \"100%\"\n",
    "]\n",
    "\n",
    "# Convert the column to a categorical type with the specified order\n",
    "df_educator_melted['percent_clinical_ordered'] = pd.Categorical(\n",
    "    df_educator_melted['In your most recently accepted offer, what is your percent clinical time?'],\n",
    "    categories=ordered_categories,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Create ordinal mapping for statistical testing\n",
    "clinical_time_map = {cat: i+1 for i, cat in enumerate(ordered_categories)}\n",
    "df_educator_melted['percent_clinical_ordinal'] = df_educator_melted['percent_clinical_ordered'].map(clinical_time_map)\n",
    "\n",
    "# Binarize for 90% clinical time or more\n",
    "df_educator_melted['clin_time_90plus'] = df_educator_melted['In your most recently accepted offer, what is your percent clinical time?'].isin(['90-99%', '100%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_proportion_plot(df, category_col, ordinal_col, group_col, \n",
    "                                 ordered_categories, group_pairs=None, \n",
    "                                 title=None, xlabel=None, ylabel='Proportion',\n",
    "                                 figsize=(6, 4), statistical_test='Mann-Whitney',\n",
    "                                 print_stats=True):\n",
    "       \n",
    "    # Prepare data for stacked bar chart\n",
    "    df_plot = df[[category_col, ordinal_col, group_col]].dropna()\n",
    "    \n",
    "    # Create crosstab for stacked bar chart\n",
    "    crosstab = pd.crosstab(df_plot[group_col], df_plot[category_col])\n",
    "    \n",
    "    # Reorder columns based on category order\n",
    "    crosstab = crosstab.reindex(columns=ordered_categories, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "    \n",
    "    flare_colors = sns.color_palette(\"flare\", n_colors=len(ordered_categories))\n",
    "\n",
    "    # Create the stacked bar plot with proportions\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=flare_colors,)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(xlabel or group_col)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title or f'Distribution of {category_col} by {group_col}')\n",
    "    ax.set_ylim(0, 1)  # Set y-axis from 0 to 1 for proportions\n",
    "    \n",
    "    # Fix legend order to match stacking order\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title=category_col.replace('_', ' ').title(), \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add statistical annotation if pairs are provided\n",
    "    if group_pairs:\n",
    "        annotator = Annotator(ax, group_pairs, data=df_plot, x=group_col, y=ordinal_col)\n",
    "        annotator.configure(test=statistical_test, loc='inside', text_format='simple')\n",
    "        annotator.apply_and_annotate()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_proportion_plot(\n",
    "    df=df_educator_melted,\n",
    "    category_col='percent_clinical_ordered',\n",
    "    ordinal_col='percent_clinical_ordinal', \n",
    "    group_col='internal_offer',\n",
    "    ordered_categories=ordered_categories,\n",
    "    group_pairs=[(True,False)],\n",
    "    title='Distribution of Clinical Time Percentage by Internal Offer',\n",
    "    xlabel='Internal Offer'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_proportion_plot(\n",
    "    df=df_educator_melted,\n",
    "    category_col='percent_clinical_ordered',\n",
    "    ordinal_col='percent_clinical_ordinal', \n",
    "    group_col='gender',\n",
    "    ordered_categories=ordered_categories,\n",
    "    group_pairs=[('Man','Woman')],\n",
    "    title='Distribution of Clinical Time Percentage by Gender',\n",
    "    xlabel='Gender'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_proportion_plot(\n",
    "    df=df_educator_melted,\n",
    "    category_col='percent_clinical_ordered',\n",
    "    ordinal_col='percent_clinical_ordinal', \n",
    "    group_col='multiple_interviews',\n",
    "    ordered_categories=ordered_categories,\n",
    "    group_pairs=[(True,False)],\n",
    "    title='Distribution of Clinical Time Percentage by Multiple Interviews',\n",
    "    xlabel='Multiple Interviews'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_proportion_plot(\n",
    "    df=df_educator_melted,\n",
    "    category_col='percent_clinical_ordered',\n",
    "    ordinal_col='percent_clinical_ordinal', \n",
    "    group_col='extra_degree',\n",
    "    ordered_categories=ordered_categories,\n",
    "    group_pairs=[(True,False)],\n",
    "    title='Distribution of Clinical Time Percentage by Extra Degree',\n",
    "    xlabel='Extra Degree'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_educator_melted['gender'],\n",
    "                                 df_educator_melted['clin_time_90plus'])\n",
    "\n",
    "fisher_exact(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_educator_melted['internal_offer'],\n",
    "                                 df_educator_melted['clin_time_90plus'])\n",
    "\n",
    "fisher_exact(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_educator_melted['extra_degree'],\n",
    "                                 df_educator_melted['clin_time_90plus'])\n",
    "\n",
    "fisher_exact(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df_educator_melted['multiple_interviews'],\n",
    "                                 df_educator_melted['clin_time_90plus'])\n",
    "\n",
    "fisher_exact(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_categories = [\n",
    "    \"Less than 50%\",\n",
    "    \"50%\",\n",
    "    \"50-75%\",\n",
    "    \"75-89%\",\n",
    "    \"90-99%\",\n",
    "    \"100%\"\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "flare_colors = sns.color_palette(\"flare\", n_colors=len(ordered_categories))\n",
    "counts = df_educator_melted['percent_clinical_ordered'].value_counts()\n",
    "counts = counts.reindex(ordered_categories)\n",
    "counts.plot(kind='barh', ax=ax, color=flare_colors, edgecolor='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('%FTE Clinical Time', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary categories for 90+ clinical time\n",
    "binary_categories = [\"<90% Clinical\", \"90% Clinical\"]\n",
    "\n",
    "# Binarize for 90% clinical time or more\n",
    "df_educator_melted['clin_time_90plus'] = df_educator_melted['In your most recently accepted offer, what is your percent clinical time?'].isin(['90-99%', '100%'])\n",
    "\n",
    "# Create a categorical column for the binary classification\n",
    "df_educator_melted['clinical_time_binary'] = df_educator_melted['clin_time_90plus'].map({\n",
    "    False: \"<90% Clinical\",\n",
    "    True: \"90% Clinical\"\n",
    "})\n",
    "\n",
    "# Convert to categorical type with specified order\n",
    "df_educator_melted['clinical_time_binary_ordered'] = pd.Categorical(\n",
    "    df_educator_melted['clinical_time_binary'],\n",
    "    categories=binary_categories,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "def create_stacked_proportion_plot_binary(df, category_col, group_col, \n",
    "                                        ordered_categories, group_pairs=None, \n",
    "                                        title=None, xlabel=None, ylabel='Proportion',\n",
    "                                        figsize=(6, 4), statistical_test='Fisher-exact',\n",
    "                                        print_stats=True):\n",
    "       \n",
    "    # Prepare data for stacked bar chart\n",
    "    df_plot = df[[category_col, group_col]].dropna()\n",
    "    \n",
    "    # Create crosstab for stacked bar chart\n",
    "    crosstab = pd.crosstab(df_plot[group_col], df_plot[category_col])\n",
    "    \n",
    "    # Reorder columns based on category order\n",
    "    crosstab = crosstab.reindex(columns=ordered_categories, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Use a simple 2-color palette for binary comparison\n",
    "    colors = [\"#793341\", \"#643F86\"] \n",
    "    \n",
    "    # Create the stacked bar plot with proportions\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=colors)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(xlabel or group_col)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title or f'Distribution of {category_col} by {group_col}')\n",
    "    ax.set_ylim(0, 1)  # Set y-axis from 0 to 1 for proportions\n",
    "    \n",
    "    # Fix legend order to match stacking order\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title='Clinical Time', \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Print Fisher's exact test results if requested\n",
    "    if print_stats and group_pairs:\n",
    "        from scipy.stats import fisher_exact\n",
    "        \n",
    "        print(\"Fisher's Exact Test Results:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Get the contingency table for Fisher's exact test\n",
    "        contingency_table = pd.crosstab(df_plot[group_col], df_plot[category_col])\n",
    "        print(\"Contingency Table:\")\n",
    "        print(contingency_table)\n",
    "        print()\n",
    "        \n",
    "        # Perform Fisher's exact test\n",
    "        oddsratio, p_value = fisher_exact(contingency_table)\n",
    "        \n",
    "        print(f\"Odds Ratio: {oddsratio:.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Interpret significance\n",
    "        if p_value < 0.001:\n",
    "            significance = \"*** (p < 0.001)\"\n",
    "        elif p_value < 0.01:\n",
    "            significance = \"** (p < 0.01)\"\n",
    "        elif p_value < 0.05:\n",
    "            significance = \"* (p < 0.05)\"\n",
    "        else:\n",
    "            significance = \"ns (not significant)\"\n",
    "            \n",
    "        print(f\"Significance: {significance}\")\n",
    "        print()\n",
    "        \n",
    "        # Calculate proportions for interpretation\n",
    "        prop_table = pd.crosstab(df_plot[group_col], df_plot[category_col], normalize='index')\n",
    "        print(\"Proportion Table (row percentages):\")\n",
    "        print(prop_table.round(3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "# Create the plot with binary clinical time categories\n",
    "fig, ax = create_stacked_proportion_plot_binary(\n",
    "    df=df_educator_melted,\n",
    "    category_col='clinical_time_binary_ordered',\n",
    "    group_col='internal_offer',\n",
    "    ordered_categories=binary_categories,\n",
    "    group_pairs=[(True, False)],\n",
    "    title='Distribution of Clinical Time (90% vs <90%)',\n",
    "    xlabel='Internal Offer',\n",
    "    print_stats=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot with binary clinical time categories\n",
    "fig, ax = create_stacked_proportion_plot_binary(\n",
    "    df=df_educator_melted,\n",
    "    category_col='clinical_time_binary_ordered',\n",
    "    group_col='extra_degree',\n",
    "    ordered_categories=binary_categories,\n",
    "    group_pairs=[(True, False)],\n",
    "    title='Distribution of Clinical Time (90% vs <90%)',\n",
    "    xlabel='extra_degree',\n",
    "    print_stats=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot with binary clinical time categories\n",
    "fig, ax = create_stacked_proportion_plot_binary(\n",
    "    df=df_educator_melted,\n",
    "    category_col='clinical_time_binary_ordered',\n",
    "    group_col='gender',\n",
    "    ordered_categories=binary_categories,\n",
    "    group_pairs=[(True, False)],\n",
    "    title='Distribution of Clinical Time (90% vs <90%)',\n",
    "    xlabel='Gender',\n",
    "    print_stats=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary categories for 90+ clinical time\n",
    "binary_categories = [\"<90% Clinical\", \"90% Clinical\"]\n",
    "\n",
    "# Binarize for 90% clinical time or more\n",
    "df_educator_melted['clin_time_90plus'] = df_educator_melted['In your most recently accepted offer, what is your percent clinical time?'].isin(['90-99%', '100%'])\n",
    "\n",
    "# Create a categorical column for the binary classification\n",
    "df_educator_melted['clinical_time_binary'] = df_educator_melted['clin_time_90plus'].map({\n",
    "    False: \"<90% Clinical\",\n",
    "    True: \"90% Clinical\"\n",
    "})\n",
    "\n",
    "# Convert to categorical type with specified order\n",
    "df_educator_melted['clinical_time_binary_ordered'] = pd.Categorical(\n",
    "    df_educator_melted['clinical_time_binary'],\n",
    "    categories=binary_categories,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "def create_stacked_proportion_plot_binary(df, category_col, group_col, \n",
    "                                        ordered_categories, group_pairs=None, \n",
    "                                        title=None, xlabel=None, ylabel='Proportion',\n",
    "                                        figsize=(6, 4), statistical_test='Fisher-exact',\n",
    "                                        print_stats=True):\n",
    "       \n",
    "    # Prepare data for stacked bar chart\n",
    "    df_plot = df[[category_col, group_col]].dropna()\n",
    "    \n",
    "    # Create crosstab for stacked bar chart\n",
    "    crosstab = pd.crosstab(df_plot[group_col], df_plot[category_col])\n",
    "    \n",
    "    # Reorder columns based on category order\n",
    "    crosstab = crosstab.reindex(columns=ordered_categories, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Use a red/purple color theme for binary comparison\n",
    "    colors = [\"#793341\", \"#643F86\"]\n",
    "    \n",
    "    # Create the stacked bar plot with proportions\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=colors)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(xlabel or group_col)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title or f'Distribution of {category_col} by {group_col}')\n",
    "    ax.set_ylim(0, 1)  # Set y-axis from 0 to 1 for proportions\n",
    "    \n",
    "    # Fix legend order to match stacking order\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title='Clinical Time', \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Print Fisher's exact test results if requested\n",
    "    if print_stats and group_pairs:\n",
    "        from scipy.stats import fisher_exact\n",
    "        \n",
    "        print(\"Fisher's Exact Test Results:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Get the contingency table for Fisher's exact test\n",
    "        contingency_table = pd.crosstab(df_plot[group_col], df_plot[category_col])\n",
    "        print(\"Contingency Table:\")\n",
    "        print(contingency_table)\n",
    "        print()\n",
    "        \n",
    "        # Perform Fisher's exact test\n",
    "        oddsratio, p_value = fisher_exact(contingency_table)\n",
    "        \n",
    "        print(f\"Odds Ratio: {oddsratio:.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Interpret significance\n",
    "        if p_value < 0.001:\n",
    "            significance = f\"*** (p < 0.001)\"\n",
    "        elif p_value < 0.01:\n",
    "            significance = f\"** (p = {p_value:.3f})\"\n",
    "        elif p_value < 0.05:\n",
    "            significance = f\"* (p = {p_value:.3f})\"\n",
    "        else:\n",
    "            significance = f\"ns (p = {p_value:.3f})\"\n",
    "            \n",
    "        print(f\"Significance: {significance}\")\n",
    "        print()\n",
    "        \n",
    "        # Calculate proportions for interpretation\n",
    "        prop_table = pd.crosstab(df_plot[group_col], df_plot[category_col], normalize='index')\n",
    "        print(\"Proportion Table (row percentages):\")\n",
    "        print(prop_table.round(3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "# Create the plot with binary clinical time categories\n",
    "fig, ax = create_stacked_proportion_plot_binary(\n",
    "    df=df_educator_melted,\n",
    "    category_col='clinical_time_binary_ordered',\n",
    "    group_col='internal_offer',\n",
    "    ordered_categories=binary_categories,\n",
    "    group_pairs=[(True, False)],\n",
    "    title='Distribution of Clinical Time (90% vs <90%) by Internal Offer',\n",
    "    xlabel='Internal Offer',\n",
    "    print_stats=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE Non-Clinical FTE Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns\n",
    "non_clinical_columns = [\n",
    "    'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))',\n",
    "    'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))', \n",
    "    'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)',\n",
    "    'What is the non-clinical full-time equivalent for? (choice=Clinical program building)',\n",
    "    'What is the non-clinical full-time equivalent for? (choice=Quality improvement)',\n",
    "    'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)',\n",
    "    'What is the non-clinical full-time equivalent for? (choice=Other)'\n",
    "]\n",
    "\n",
    "# Create shorter labels for better visualization\n",
    "short_labels = [\n",
    "    'GME Role\\n(Program Director)',\n",
    "    'UME Role\\n(Clerkship Director)', \n",
    "    'Other Medical\\nEducator Role',\n",
    "    'Clinical Program\\nBuilding',\n",
    "    'Quality\\nImprovement',\n",
    "    'Clinical Admin\\nDuties',\n",
    "    'Other'\n",
    "]\n",
    "\n",
    "# Count 'Checked' responses for each column\n",
    "checked_counts = []\n",
    "for i, col in enumerate(non_clinical_columns):\n",
    "    if col == 'CME Role': # This column is commented out in the TableOne, so explicitly handle it\n",
    "        checked_count = 0\n",
    "    else:\n",
    "        checked_count = (df_educator_melted[col] == 'Checked').sum()\n",
    "    checked_counts.append(checked_count)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'Role': short_labels,\n",
    "    'Checked_Count': checked_counts\n",
    "})\n",
    "\n",
    "# Sort by count (optional)\n",
    "plot_data = plot_data.sort_values('Checked_Count', ascending=False)\n",
    "\n",
    "# Horizontal bar plot for better label readability\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "bars = ax.barh(range(len(plot_data)), plot_data['Checked_Count'],\n",
    "               color='#A0306E',\n",
    "               edgecolor='black', linewidth=0.5)\n",
    "\n",
    "ax.set_title('Non-Clinical FTE Roles')\n",
    "ax.set_xlabel('Number of offers with these roles')\n",
    "# Set y-axis labels\n",
    "ax.set_yticks(range(len(plot_data)))\n",
    "ax.set_yticklabels(plot_data['Role'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE Job Offers TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ 'What geographic region is the institution?',\n",
    "       'Cost of living at institution of job negotiation',\n",
    "       'What salary range were you offered?',\n",
    "       'Did your initial contract include non-clinical FTE (e.g. Quality, safety, education, clinical program building)?',\n",
    "       'In your most recently accepted offer, what is your percent clinical time?',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=GME role (e.g., residency or fellowship program director))',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=UME role (e.g., med student clerkship director))', \n",
    "      #  'What is the non-clinical full-time equivalent for? (choice=CME role)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Other medical educator role)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Clinical program building)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Quality improvement)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Clinical administrative duties)',\n",
    "       'What is the non-clinical full-time equivalent for? (choice=Other)',\n",
    "       'Did you receive non-clinical FTE?',\n",
    "       'Do you have additional FTE dedicated for research?',\n",
    "          'Is your salary adjusted based on your clinical effort (e.g., number of patients or RVUs)?',\n",
    "       'Is there transparency about how salary equity is evaluated at this institution?',\n",
    "       'Were any signing bonuses or performance-based incentives part of your negotiation?',\n",
    "       'Value of bonuses/incentives', 'Were you offered a relocation package?',\n",
    "       'If yes, what was the total value of the relocation package?',\n",
    "       'Do you have a noncompete clause?',\n",
    "       'clinical_time_binary_ordered',\n",
    "       ]\n",
    "\n",
    "\n",
    "\n",
    "# Generate TableOne\n",
    "table1 = TableOne(df_educator_melted, columns=columns, categorical=columns,  rename=None, groupby='clinical_time_binary_ordered', pval=True)\n",
    "# table1.to_csv('table1_job_offers_educator_byGender.csv')\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE Salary Range and Clinical Time Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ordered categories for salary (CE specific)\n",
    "salary_categories = [\n",
    "    'Less than $150,000',\n",
    "    '$150,000-$199,999',\n",
    "    '$200,000-$249,999',\n",
    "    '$250,000-$299,999',\n",
    "    '$300,000-$349,999',\n",
    "    '$350,000-$399,999',\n",
    "    'More than $400,000'\n",
    "]\n",
    "\n",
    "# Convert to categorical with ordering\n",
    "df_educator_melted['salary_range_ordered'] = pd.Categorical(df_educator_melted['What salary range were you offered?'], categories=salary_categories, ordered=True)\n",
    "df_educator_melted['salary_range_ordered'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the heatmap for clinical time vs. salary range\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "sns.heatmap(\n",
    "    pd.crosstab(df_educator_melted['percent_clinical_ordered'],\n",
    "               df_educator_melted['salary_range_ordered']).dropna(),\n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='flare',  \n",
    "    linecolor='white',\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Number of Responses'},\n",
    "    square=False,\n",
    "    annot_kws={'fontsize': 10, }\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of Clinical Time vs Salary Range', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Salary Range', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Percent Clinical Time', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Salary Data Analysis (PS and CE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scientist_melted_salary = df_scientist_melted[[ 'gender',\n",
    " 'Type of Job Most Recently Accepted','internal_offer', 'salary_range_offered',\n",
    "                                                'extra_degree','multiple_interviews',\n",
    " 'What geographic region is the institution?',\n",
    " 'Cost of living at institution (example cities)',\n",
    " 'Were any signing bonuses or performance-based incentives part of your negotiation?',\n",
    " 'If yes, what is the approximate total value of these bonuses/incentives?',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_educator_melted_salary = df_educator_melted[['gender',\n",
    " 'Type of Job Most Recently Accepted','internal_offer', 'salary_range_ordered',\n",
    "                                                'extra_degree','multiple_interviews',\n",
    " 'What geographic region is the institution?',\n",
    " 'Cost of living at institution of job negotiation',\n",
    " 'Were any signing bonuses or performance-based incentives part of your negotiation?',\n",
    " 'Value of bonuses/incentives',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize the column names to match between dataframes\n",
    "\n",
    "# Rename columns in df_educator_melted_salary to match df_scientist_melted_salary\n",
    "df_educator_melted_salary = df_educator_melted_salary.rename(columns={\n",
    "    'salary_range_ordered': 'salary_range_offered',\n",
    "    'Cost of living at institution of job negotiation': 'Cost of living at institution (example cities)',\n",
    "    'Value of bonuses/incentives': 'If yes, what is the approximate total value of these bonuses/incentives?'\n",
    "})\n",
    "\n",
    "# Concatenate with standardized names\n",
    "df_combined_salary = pd.concat([df_scientist_melted_salary, df_educator_melted_salary], \n",
    "                              ignore_index=True)\n",
    "\n",
    "print(\"Combined dataframe shape:\", df_combined_salary.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_combined_salary.columns.tolist())\n",
    "\n",
    "# Define a mapping for standardized column names for cleaner, shorter names\n",
    "column_mapping = {\n",
    "    'Type of Job Most Recently Accepted': 'job_type',\n",
    "    'internal_offer': 'internal_offer',\n",
    "    'salary_range_offered': 'salary_range',  # scientist version\n",
    "    'salary_range_ordered': 'salary_range',  # educator version  \n",
    "    'extra_degree': 'extra_degree',\n",
    "    'multiple_interviews': 'multiple_interviews',\n",
    "    'What geographic region is the institution?': 'geographic_region',\n",
    "    'Cost of living at institution (example cities)': 'cost_of_living',  # scientist version\n",
    "    'Cost of living at institution of job negotiation': 'cost_of_living',  # educator version\n",
    "    'Were any signing bonuses or performance-based incentives part of your negotiation?': 'has_bonuses',\n",
    "    'If yes, what is the approximate total value of these bonuses/incentives?': 'bonus_value',  # scientist version\n",
    "    'Value of bonuses/incentives': 'bonus_value'  # educator version\n",
    "}\n",
    "\n",
    "# Apply standardized names to both dataframes\n",
    "df_scientist_standardized = df_scientist_melted_salary.rename(columns=column_mapping)\n",
    "df_educator_standardized = df_educator_melted_salary.rename(columns=column_mapping)\n",
    "\n",
    "# Concatenate with standardized names\n",
    "df_combined_standardized = pd.concat([df_scientist_standardized, df_educator_standardized], \n",
    "                                   ignore_index=True)\n",
    "\n",
    "print(\"\\nStandardized combined dataframe shape:\", df_combined_standardized.shape)\n",
    "print(\"\\nStandardized column names:\")\n",
    "print(df_combined_standardized.columns.tolist())\n",
    "\n",
    "# Match PS granularity with CE granularity for salary ranges\n",
    "df_combined_standardized.replace({\n",
    "    '$300,000-$349,999': 'More than $300,000',\n",
    "    '$350,000-$399,999': 'More than $300,000',\n",
    "    'More than $400,000': 'More than $300,000'\n",
    "}, inplace=True)\n",
    "\n",
    "# Define the ordered categories for salary for the combined dataframe\n",
    "salary_categories = [\n",
    "    'Less than $150,000',\n",
    "    '$150,000-$199,999',\n",
    "    '$200,000-$249,999',\n",
    "    '$250,000-$299,999',\n",
    "    'More than $300,000'\n",
    "]\n",
    "\n",
    "# Convert to categorical with ordering\n",
    "df_combined_standardized['salary_range'] = pd.Categorical(df_combined_standardized['salary_range'], categories=salary_categories, ordered=True)\n",
    "salary_map = {\n",
    "    'Less than $150,000': 1,\n",
    "    '$150,000-$199,999': 2,\n",
    "    '$200,000-$249,999': 3,\n",
    "    '$250,000-$299,999': 4,\n",
    "    'More than $300,000': 5\n",
    "}\n",
    "\n",
    "df_combined_standardized['salary_ordinal'] = df_combined_standardized['salary_range'].map(salary_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_standardized.to_csv('df_combined_salary_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Salary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "# Define pastel rainbow colors (assuming these are defined in your environment)\n",
    "# If not defined, uncomment the line below:\n",
    "# pastel_rainbow = ['#FFB3BA', '#FFDFBA', '#FFFFBA', '#BAFFC9', '#BAE1FF', '#D4BAFF']\n",
    "\n",
    "def create_stacked_bar_subplot(ax, data, x_col, y_col, order=None, pairs=None,\n",
    "                               test='Mann-Whitney', loc='inside', text_format='simple',\n",
    "                               title=None, xlabel=None, subplot_label=None):\n",
    "    \"\"\"\n",
    "    Create a stacked bar chart in a subplot with statistical annotations\n",
    "    \"\"\"\n",
    "    # Create salary mapping (consistent for combined data)\n",
    "    salary_map = {\n",
    "        'Less than $150,000': 1,\n",
    "        '$150,000-$199,999': 2,\n",
    "        '$200,000-$249,999': 3,\n",
    "        '$250,000-$299,999': 4,\n",
    "        'More than $300,000': 5\n",
    "    }\n",
    "    \n",
    "    # Create reverse mapping for labels\n",
    "    reverse_salary_map = {v: k for k, v in salary_map.items()}\n",
    "    \n",
    "    # Prepare data for stacked bar chart\n",
    "    df_plot = data.copy()\n",
    "    df_plot['salary_range_text'] = df_plot[y_col].map(reverse_salary_map)\n",
    "    \n",
    "    # Create crosstab for stacked bar chart\n",
    "    crosstab = pd.crosstab(df_plot[x_col], df_plot['salary_range_text'])\n",
    "    \n",
    "    # Reorder columns based on salary_ordinal order\n",
    "    salary_order = [reverse_salary_map[i] for i in sorted(reverse_salary_map.keys())]\n",
    "    crosstab = crosstab.reindex(columns=salary_order, fill_value=0)\n",
    "    \n",
    "    # Reorder rows if order is specified\n",
    "    if order:\n",
    "        crosstab = crosstab.reindex(order, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Create the stacked bar plot\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=pastel_rainbow, legend=False)\n",
    "    \n",
    "    # Add subplot label (A, B, C, D)\n",
    "    if subplot_label:\n",
    "        ax.text(-0.15, 1.05, subplot_label, transform=ax.transAxes,\n",
    "                fontsize=16, fontweight='bold', va='top')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(xlabel or x_col, fontsize=12)\n",
    "    ax.set_ylabel('Proportion', fontsize=12)\n",
    "    ax.set_title(title or f'Distribution by {x_col}', fontsize=13)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=0, labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    \n",
    "    # Add sample sizes (n) below x-tick labels\n",
    "    sample_sizes = crosstab.sum(axis=1)\n",
    "    \n",
    "    # Get the actual category labels from the crosstab index\n",
    "    categories = crosstab.index.tolist()\n",
    "    \n",
    "    # Create new labels with sample sizes\n",
    "    new_labels = []\n",
    "    for i, cat in enumerate(categories):\n",
    "        n_value = int(sample_sizes.iloc[i])\n",
    "        # Format the label based on the type of data\n",
    "        if isinstance(cat, bool):\n",
    "            label_text = 'Yes' if cat else 'No'\n",
    "        else:\n",
    "            label_text = str(cat)\n",
    "        new_labels.append(f'{label_text}\\n(n={n_value})')\n",
    "    \n",
    "    ax.set_xticklabels(new_labels, fontsize=10, rotation=0)\n",
    "    \n",
    "    # Add statistical annotation if pairs are provided\n",
    "    if pairs:\n",
    "        annotator = Annotator(ax, pairs, data=data, x=x_col, y=y_col, order=order)\n",
    "        annotator.configure(test=test, loc=loc, text_format=text_format)\n",
    "        annotator.apply_and_annotate()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# Create the main figure with 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Salary Distribution Comparisons', fontsize=16, fontweight='bold', y=1.0)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# (A) Physician-scientists vs Clinician-educator\n",
    "create_stacked_bar_subplot(\n",
    "    axes[0],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='job_type',\n",
    "    y_col='salary_ordinal',\n",
    "    order=['Physician scientist', 'Clinician educator'],\n",
    "    pairs=[('Physician scientist', 'Clinician educator')],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Physician Scientist vs Clinician Educator',\n",
    "    xlabel='Job Type',\n",
    "    subplot_label='A)'\n",
    ")\n",
    "\n",
    "# (B) Internal vs External job offer\n",
    "ax1 = create_stacked_bar_subplot(\n",
    "    axes[1],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='internal_offer',\n",
    "    y_col='salary_ordinal',\n",
    "    order=[True, False],\n",
    "    pairs=[(True, False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Internal vs External Job Offer',\n",
    "    xlabel='Internal Offer',\n",
    "    subplot_label='B)'\n",
    ")\n",
    "\n",
    "# Fix labels for Boolean values in subplot B\n",
    "current_labels = [label.get_text() for label in ax1.get_xticklabels()]\n",
    "new_labels_b = []\n",
    "for label in current_labels:\n",
    "    if 'Yes' in label:\n",
    "        new_labels_b.append(label.replace('Yes', 'Internal'))\n",
    "    elif 'No' in label:\n",
    "        new_labels_b.append(label.replace('No', 'External'))\n",
    "    else:\n",
    "        new_labels_b.append(label)\n",
    "ax1.set_xticklabels(new_labels_b, fontsize=10, rotation=0)\n",
    "\n",
    "# (C) Additional degree vs No additional degree\n",
    "ax2 = create_stacked_bar_subplot(\n",
    "    axes[2],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='extra_degree',\n",
    "    y_col='salary_ordinal',\n",
    "    order=[True, False],\n",
    "    pairs=[(True, False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Additional Degree (MS, PhD, etc.)',\n",
    "    xlabel='Has Additional Degree',\n",
    "    subplot_label='C)'\n",
    ")\n",
    "\n",
    "# Fix labels for Boolean values in subplot C\n",
    "current_labels = [label.get_text() for label in ax2.get_xticklabels()]\n",
    "new_labels_c = []\n",
    "for label in current_labels:\n",
    "    if 'Yes' in label:\n",
    "        new_labels_c.append(label.replace('Yes', 'Additional Degree'))\n",
    "    elif 'No' in label:\n",
    "        new_labels_c.append(label.replace('No', 'No Additional Degree'))\n",
    "    else:\n",
    "        new_labels_c.append(label)\n",
    "ax2.set_xticklabels(new_labels_c, fontsize=10, rotation=0)\n",
    "\n",
    "# (D) Multiple offers vs Single offer\n",
    "ax3 = create_stacked_bar_subplot(\n",
    "    axes[3],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='multiple_interviews',  # Assuming this should be 'multiple_offers' based on your description\n",
    "    y_col='salary_ordinal',\n",
    "    order=[True, False],\n",
    "    pairs=[(True, False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Multiple Offers vs Single Offer',\n",
    "    xlabel='Received Multiple Offers',\n",
    "    subplot_label='D)'\n",
    ")\n",
    "\n",
    "# Fix labels for Boolean values in subplot D\n",
    "current_labels = [label.get_text() for label in ax3.get_xticklabels()]\n",
    "new_labels_d = []\n",
    "for label in current_labels:\n",
    "    if 'Yes' in label:\n",
    "        new_labels_d.append(label.replace('Yes', 'Multiple Offers'))\n",
    "    elif 'No' in label:\n",
    "        new_labels_d.append(label.replace('No', 'Single Offer'))\n",
    "    else:\n",
    "        new_labels_d.append(label)\n",
    "ax3.set_xticklabels(new_labels_d, fontsize=10, rotation=0)\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "# Get legend handles and labels from the first subplot\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "# Reverse order to match stacking order\n",
    "fig.legend(reversed(handles), reversed(labels), \n",
    "           title='Salary Range',\n",
    "           bbox_to_anchor=(0.95, .9), \n",
    "           loc='upper left',\n",
    "           fontsize=11,\n",
    "           title_fontsize=12)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 0.92, 0.98])  # Leave space for legend on the right\n",
    "\n",
    "plt.savefig('fig_salary_distribution_subplots.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Alternative: Save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_map = {\n",
    "        'Less than $150,000': 1,\n",
    "        '$150,000-$199,999': 2,\n",
    "        '$200,000-$249,999': 3,\n",
    "        '$250,000-$299,999': 4,\n",
    "        'More than $300,000': 5\n",
    "    }\n",
    "\n",
    "df_combined_standardized.salary_ordinal.astype('float64').groupby(df_combined_standardized['job_type']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactored create_stacked_bar_with_stats for combined data\n",
    "def create_stacked_bar_with_stats_combined(data, x_col, y_col, order=None, pairs=None, \n",
    "                                 test='Mann-Whitney', loc='outside', \n",
    "                                 text_format='simple', figsize=(7, 4), title=None, xlabel=None):\n",
    "    \n",
    "    # Create salary mapping (consistent for combined data)\n",
    "    salary_map = {\n",
    "        'Less than $150,000': 1,\n",
    "        '$150,000-$199,999': 2,\n",
    "        '$200,000-$249,999': 3,\n",
    "        '$250,000-$299,999': 4,\n",
    "        'More than $300,000': 5\n",
    "    }\n",
    "    \n",
    "    # Create reverse mapping for labels\n",
    "    reverse_salary_map = {v: k for k, v in salary_map.items()}\n",
    "    \n",
    "    # Prepare data for stacked bar chart\n",
    "    df_plot = data.copy()\n",
    "    df_plot['salary_range_text'] = df_plot[y_col].map(reverse_salary_map)\n",
    "    \n",
    "    # Create crosstab for stacked bar chart\n",
    "    crosstab = pd.crosstab(df_plot[x_col], df_plot['salary_range_text'])\n",
    "    \n",
    "    # Reorder columns based on salary_ordinal order\n",
    "    salary_order = [reverse_salary_map[i] for i in sorted(reverse_salary_map.keys())]\n",
    "    crosstab = crosstab.reindex(columns=salary_order, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "\n",
    "    # Create the stacked bar plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=pastel_rainbow)\n",
    "    \n",
    "    # Customize the plot with larger font sizes\n",
    "    ax.set_xlabel(xlabel or x_col, fontsize=14)\n",
    "    ax.set_ylabel('Proportion', fontsize=14)\n",
    "    ax.set_title(title or f'Distribution of Salary Ranges by {x_col}', fontsize=16)\n",
    "    ax.set_ylim(0, 1)  # Set y-axis from 0 to 1 for proportions\n",
    "    \n",
    "    # Fix legend order to match stacking order (flip it)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(reversed(handles), reversed(labels), title='Salary Range', \n",
    "              bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12, title_fontsize=13)\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=0, labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    # Add sample sizes (n) below x-tick labels\n",
    "    x_labels = ax.get_xticklabels()\n",
    "    sample_sizes = crosstab.sum(axis=1)  # Get total counts for each category\n",
    "    \n",
    "    # Update x-tick labels to include sample sizes\n",
    "    new_labels = []\n",
    "    for i, label in enumerate(x_labels):\n",
    "        original_text = label.get_text()\n",
    "        n_value = sample_sizes.iloc[i] if i < len(sample_sizes) else 0\n",
    "        new_labels.append(f'{original_text}\\n(n={n_value})')\n",
    "    \n",
    "    ax.set_xticklabels(new_labels, fontsize=12)\n",
    "    \n",
    "    # Add statistical annotation if pairs are provided\n",
    "    if pairs:\n",
    "        annotator = Annotator(ax, pairs, data=data, x=x_col, y=y_col, order=order)\n",
    "        annotator.configure(test=test, loc=loc, text_format=text_format)\n",
    "        annotator.apply_and_annotate()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "# Plot for job type vs. salary (combined data)\n",
    "fig, ax = create_stacked_bar_with_stats_combined(\n",
    "    data=df_combined_standardized, \n",
    "    x_col='job_type', \n",
    "    y_col='salary_ordinal', \n",
    "    order=['Physician scientist', 'Clinician educator'], \n",
    "    pairs=[('Physician scientist', 'Clinician educator')],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside', \n",
    "    text_format='simple', \n",
    "    figsize=(7, 4),\n",
    "    title='Salary Offers by Job Type',\n",
    "    xlabel='Job Type'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for gender vs. salary (combined data)\n",
    "fig, ax = create_stacked_bar_with_stats_combined(\n",
    "    data=df_combined_standardized, \n",
    "    x_col='gender', \n",
    "    y_col='salary_ordinal', \n",
    "    order=['Man', 'Woman'], \n",
    "    pairs=[('Man', 'Woman')],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges, All Jobs'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for multiple interviews vs. salary (combined data)\n",
    "fig, ax = create_stacked_bar_with_stats_combined(\n",
    "    df_combined_standardized,\n",
    "    y_col='salary_ordinal',\n",
    "    x_col='multiple_interviews',\n",
    "    order=[True,False],\n",
    "    pairs=[(True,False)],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges, All Jobs'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for extra degree vs. salary (combined data)\n",
    "fig, ax = create_stacked_bar_with_stats_combined(\n",
    "    df_combined_standardized,\n",
    "    y_col='salary_ordinal',\n",
    "    x_col='extra_degree',\n",
    "    order=[True,False],\n",
    "    pairs=[(True,False)],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges, All Jobs'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for internal offer vs. salary (combined data)\n",
    "fig, ax = create_stacked_bar_with_stats_combined(\n",
    "    df_combined_standardized,\n",
    "    y_col='salary_ordinal',\n",
    "    x_col='internal_offer',\n",
    "    order=[True,False],\n",
    "    pairs=[(True,False)],\n",
    "    test='Mann-Whitney',loc='inside', \n",
    "    text_format='simple', figsize=(7, 4),\n",
    "    title='Distribution of Salary Ranges, All Jobs'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify geographic region and cost of living categories\n",
    "geographic_region_map = {\n",
    "    'Midwest (IL, IN, MI, OH, WI, IA, KS, MN, MO, NE, ND, SD)': 'Midwest',\n",
    "    'Northeast (CT, ME, MA, NH, RI, VT, NJ, NY, PA)': 'Northeast', \n",
    "    'West (AZ, CO, ID, MT, NV, NM, UT, WY, AK, CA, HI, OR, WA)': 'West',\n",
    "    'South (DE, DC, FL, GA, MD, NC, SC, VA, WV, AL, KY, MS, TN, AR, LA, OK, TX)': 'South'\n",
    "}\n",
    "\n",
    "df_combined_standardized['geographic_region_simple'] = df_combined_standardized['geographic_region'].map(geographic_region_map)\n",
    "\n",
    "cost_living_map = {\n",
    "    'Medium (e.g., Columbus, OH)': 'Medium',\n",
    "    'High (e.g., New York, NY; San Francisco, CA)': 'High',\n",
    "    'High (e.g., New York, NY; San Francisco, CA; Chicago, IL)': 'High',\n",
    "    'Low (e.g., Wichita, KS)': 'Low'\n",
    "}\n",
    "\n",
    "df_combined_standardized['cost_of_living_simple'] = df_combined_standardized['cost_of_living'].map(cost_living_map)\n",
    "\n",
    "# Convert to categorical with proper ordering (Low -> Medium -> High)\n",
    "df_combined_standardized['cost_of_living_categorical'] = pd.Categorical(\n",
    "    df_combined_standardized['cost_of_living_simple'], \n",
    "    categories=['Low', 'Medium', 'High'], \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Plot for geographic region vs. salary (combined data)\n",
    "fig, ax = create_stacked_bar_with_stats_combined(df_combined_standardized, 'geographic_region_simple', 'salary_ordinal',\n",
    "                                        title='Distribution of Salary Ranges by Geographic Region',\n",
    "                                        xlabel='Geographic Region'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.multitest\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "data = df_combined_standardized\n",
    "x = 'geographic_region_simple'\n",
    "y = 'salary_ordinal'\n",
    "\n",
    "# Remove any rows with missing values in the columns we're using\n",
    "data_clean = data[[x, y]].dropna()\n",
    "\n",
    "stats_results = []\n",
    "\n",
    "# Perform pairwise Mann-Whitney U tests\n",
    "for d1, d2 in itertools.combinations(data_clean[x].unique(), 2):\n",
    "    days1 = data_clean[y][data_clean[x]==d1].dropna()\n",
    "    days2 = data_clean[y][data_clean[x]==d2].dropna()\n",
    "    if days1.size == 0 or days2.size == 0:\n",
    "        continue\n",
    "    pval = scipy.stats.mannwhitneyu(days1, days2).pvalue\n",
    "    stats_results.append([d1, d2, days1.size, days2.size, pval])\n",
    "\n",
    "# Convert to DataFrame\n",
    "stats_results = pd.DataFrame(stats_results, columns=[\"group1\", \"group2\",\n",
    "                                                   \"group1_size\", \"group2_size\", \"pval\"])\n",
    "\n",
    "# Apply FDR correction\n",
    "stats_results[\"pval_adj\"] = statsmodels.stats.multitest.fdrcorrection(stats_results.pval, alpha=0.05)[1]\n",
    "\n",
    "# Get significant results\n",
    "stat_results_sign = stats_results.loc[stats_results.pval_adj < 0.05, :]\n",
    "\n",
    "# Create pairs for annotation\n",
    "pairs = []\n",
    "for _, r in stat_results_sign.iterrows():\n",
    "    pairs.append((r.group1, r.group2))\n",
    "\n",
    "# Create the box plot\n",
    "sns.boxplot(data=data_clean, x=x, y=y, ax=ax, )\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Geographic Region', fontsize=12)\n",
    "ax.set_ylabel('Salary Range (Ordinal)', fontsize=12)\n",
    "ax.set_title('Salary Distribution by Geographic Region', fontsize=14)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "ax.tick_params(axis='x', labelsize=11)\n",
    "trans = mpl.transforms.Affine2D().translate(6, 0)\n",
    "for t in ax.get_xticklabels():\n",
    "    t.set_rotation(15)\n",
    "    t.set_horizontalalignment(\"right\")\n",
    "    t.set_transform(t.get_transform() + trans)\n",
    "\n",
    "# Add statistical annotations if there are significant pairs\n",
    "if len(pairs) > 0:\n",
    "    annotator = Annotator(\n",
    "        ax, \n",
    "        pairs, \n",
    "        data=data_clean, \n",
    "        x=x,\n",
    "        y=y, \n",
    "        verbose=False\n",
    "    )\n",
    "    annotator._verbose = False\n",
    "    annotator.configure(line_width=1)\n",
    "    annotator.set_custom_annotations([f\"p={x:.2e}\" for x in stat_results_sign.pval_adj])\n",
    "    annotator.annotate()\n",
    "else:\n",
    "    print(\"No significant pairwise differences found after FDR correction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "data = df_combined_standardized\n",
    "x = 'cost_of_living_simple'\n",
    "y = 'salary_ordinal'\n",
    "\n",
    "# Remove any rows with missing values in the columns we're using\n",
    "data_clean = data[[x, y]].dropna()\n",
    "\n",
    "stats_results = []\n",
    "\n",
    "# Perform pairwise Mann-Whitney U tests\n",
    "for d1, d2 in itertools.combinations(data_clean[x].unique(), 2):\n",
    "    days1 = data_clean[y][data_clean[x]==d1].dropna()\n",
    "    days2 = data_clean[y][data_clean[x]==d2].dropna()\n",
    "    if days1.size == 0 or days2.size == 0:\n",
    "        continue\n",
    "    pval = scipy.stats.mannwhitneyu(days1, days2).pvalue\n",
    "    stats_results.append([d1, d2, days1.size, days2.size, pval])\n",
    "\n",
    "# Convert to DataFrame\n",
    "stats_results = pd.DataFrame(stats_results, columns=[\"group1\", \"group2\",\n",
    "                                                   \"group1_size\", \"group2_size\", \"pval\"])\n",
    "\n",
    "# Apply FDR correction\n",
    "stats_results[\"pval_adj\"] = statsmodels.stats.multitest.fdrcorrection(stats_results.pval, alpha=0.05)[1]\n",
    "\n",
    "# Get significant results\n",
    "stat_results_sign = stats_results.loc[stats_results.pval_adj < 0.05, :]\n",
    "\n",
    "# Create pairs for annotation\n",
    "pairs = []\n",
    "for _, r in stat_results_sign.iterrows():\n",
    "    pairs.append((r.group1, r.group2))\n",
    "\n",
    "# Create the box plot\n",
    "sns.boxplot(data=data_clean, x=x, y=y, ax=ax, )\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Cost of Living', fontsize=12)\n",
    "ax.set_ylabel('Salary Range (Ordinal)', fontsize=12)\n",
    "ax.set_title('Salary Distribution by Cost of Living', fontsize=14)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "ax.tick_params(axis='x', labelsize=11)\n",
    "trans = mpl.transforms.Affine2D().translate(6, 0)\n",
    "for t in ax.get_xticklabels():\n",
    "    t.set_rotation(15)\n",
    "    t.set_horizontalalignment(\"right\")\n",
    "    t.set_transform(t.get_transform() + trans)\n",
    "\n",
    "# Add statistical annotations if there are significant pairs\n",
    "if len(pairs) > 0:\n",
    "    annotator = Annotator(\n",
    "        ax, \n",
    "        pairs, \n",
    "        data=data_clean, \n",
    "        x=x,\n",
    "        y=y, \n",
    "        verbose=False\n",
    "    )\n",
    "    annotator._verbose = False\n",
    "    annotator.configure(line_width=1)\n",
    "    annotator.set_custom_annotations([f\"p={x:.3f}\" for x in stat_results_sign.pval_adj])\n",
    "    annotator.annotate()\n",
    "else:\n",
    "    print(\"No significant pairwise differences found after FDR correction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# Set up variables\n",
    "x = \"cost_of_living_simple\"\n",
    "y = \"salary_ordinal\"\n",
    "order = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Create reverse mapping for labels\n",
    "reverse_salary_map = {v: k for k, v in salary_map.items()}\n",
    "\n",
    "# Prepare data for stacked bar chart\n",
    "df_plot = df_combined_standardized.copy()\n",
    "df_plot['salary_range'] = df_plot[y].map(reverse_salary_map)\n",
    "df_plot['salary_numeric'] = df_plot[y].map(salary_map)\n",
    "\n",
    "# Create crosstab for stacked bar chart\n",
    "crosstab = pd.crosstab(df_plot[x], df_plot['salary_range'])\n",
    "\n",
    "# Convert to proportions\n",
    "crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "\n",
    "# Reorder columns based on salary_ordinal order\n",
    "salary_order = [reverse_salary_map[i] for i in sorted(reverse_salary_map.keys())]\n",
    "crosstab_prop = crosstab_prop.reindex(columns=salary_order, fill_value=0)\n",
    "\n",
    "# Reorder rows (x-axis) based on order parameter\n",
    "if order is not None:\n",
    "    crosstab_prop = crosstab_prop.reindex(index=order, fill_value=0)\n",
    "\n",
    "# Create the stacked bar plot\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=pastel_rainbow)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel(x)\n",
    "ax.set_ylabel('Proportion')\n",
    "ax.set_title(f'Distribution of Salary Ranges by {x}')\n",
    "ax.legend(title='Salary Range', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "annot = Annotator(ax, [(\"Low\", \"Medium\"), (\"Low\", \"High\")], data=df_combined_standardized, x=x, y=y, order=order)\n",
    "annot.configure(test='Mann-Whitney', text_format='simple', loc='inside', verbose=2)\n",
    "annot.apply_test()\n",
    "ax, test_results = annot.annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_standardized['bonus_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_standardized['has_bonuses'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "\n",
    "pastel_rainbow = [\n",
    "    \"#F0C2C2\",  # soft coral pink\n",
    "    \"#F0D2B8\",  # soft peach\n",
    "    \"#FFFFBA\",  # soft butter yellow\n",
    "    \"#C2F0C8\",  # soft mint green\n",
    "    \"#C2D8F0\",  # soft sky blue\n",
    "    \"#D8C2F0\"   # soft lilac\n",
    "]\n",
    "\n",
    "def create_stacked_bar_subplot(ax, data, x_col, y_col, order=None, pairs=None,\n",
    "                               test='Mann-Whitney', loc='inside', text_format='simple',\n",
    "                               title=None, xlabel=None, subplot_label=None):\n",
    "    \"\"\"\n",
    "    Create a stacked bar chart in a subplot with statistical annotations\n",
    "    \"\"\"\n",
    "    # Create salary mapping (consistent for combined data)\n",
    "    salary_map = {\n",
    "        'Less than $150,000': 1,\n",
    "        '$150,000-$199,999': 2,\n",
    "        '$200,000-$249,999': 3,\n",
    "        '$250,000-$299,999': 4,\n",
    "        'More than $300,000': 5\n",
    "    }\n",
    "    \n",
    "    # Create reverse mapping for labels\n",
    "    reverse_salary_map = {v: k for k, v in salary_map.items()}\n",
    "    \n",
    "    # Prepare data for stacked bar chart\n",
    "    df_plot = data.copy()\n",
    "    df_plot['salary_range_text'] = df_plot[y_col].map(reverse_salary_map)\n",
    "    \n",
    "    # Create crosstab for stacked bar chart\n",
    "    crosstab = pd.crosstab(df_plot[x_col], df_plot['salary_range_text'])\n",
    "    \n",
    "    # Reorder columns based on salary_ordinal order\n",
    "    salary_order = [reverse_salary_map[i] for i in sorted(reverse_salary_map.keys())]\n",
    "    crosstab = crosstab.reindex(columns=salary_order, fill_value=0)\n",
    "    \n",
    "    # Reorder rows if order is specified\n",
    "    if order:\n",
    "        crosstab = crosstab.reindex(order, fill_value=0)\n",
    "    \n",
    "    # Convert to proportions\n",
    "    crosstab_prop = crosstab.div(crosstab.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Create the stacked bar plot\n",
    "    crosstab_prop.plot(kind='bar', stacked=True, ax=ax, color=pastel_rainbow, legend=False)\n",
    "    \n",
    "    # Add subplot label (A, B, C, D)\n",
    "    if subplot_label:\n",
    "        ax.text(-0.05, 1.09, subplot_label, transform=ax.transAxes,\n",
    "                fontsize=16, fontweight='bold', va='top')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_xlabel(xlabel or x_col, fontsize=14)\n",
    "    ax.set_ylabel('Proportion', fontsize=14)\n",
    "    ax.set_title(title or f'Distribution by {x_col}', fontsize=13)\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    ax.tick_params(axis='x', rotation=0, labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "    # Add sample sizes (n) below x-tick labels\n",
    "    sample_sizes = crosstab.sum(axis=1)\n",
    "    \n",
    "    # Get the actual category labels from the crosstab index\n",
    "    categories = crosstab.index.tolist()\n",
    "    \n",
    "    # Create new labels with sample sizes\n",
    "    new_labels = []\n",
    "    for i, cat in enumerate(categories):\n",
    "        n_value = int(sample_sizes.iloc[i])\n",
    "        # Format the label based on the type of data\n",
    "        if isinstance(cat, bool):\n",
    "            label_text = 'Yes' if cat else 'No'\n",
    "        else:\n",
    "            label_text = str(cat)\n",
    "        new_labels.append(f'{label_text}\\n(n={n_value})')\n",
    "    \n",
    "    ax.set_xticklabels(new_labels, fontsize=16, rotation=0)\n",
    "    \n",
    "    # Add statistical annotation if pairs are provided\n",
    "    if pairs:\n",
    "        annotator = Annotator(ax, pairs, data=data, x=x_col, y=y_col, order=order)\n",
    "        annotator.configure(test=test, loc=loc, text_format=text_format, \n",
    "                           comparisons_correction='bonferroni')\n",
    "        annotator.apply_and_annotate()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "# Create the main figure with 3x2 subplots (5 panels total)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 16))\n",
    "fig.suptitle('Salary Distribution Comparisons', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "# Flatten axes for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# (A) Physician-scientists vs Clinician-educator\n",
    "create_stacked_bar_subplot(\n",
    "    axes[0],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='job_type',\n",
    "    y_col='salary_ordinal',\n",
    "    order=['Physician scientist', 'Clinician educator'],\n",
    "    pairs=[('Physician scientist', 'Clinician educator')],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Physician Scientist vs Clinician Educator',\n",
    "    xlabel='Job Type',\n",
    "    subplot_label='A)'\n",
    ")\n",
    "\n",
    "# (B) Internal vs External job offer\n",
    "ax1 = create_stacked_bar_subplot(\n",
    "    axes[1],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='internal_offer',\n",
    "    y_col='salary_ordinal',\n",
    "    order=[True, False],\n",
    "    pairs=[(True, False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Internal vs External Job Offer',\n",
    "    xlabel='Internal Offer',\n",
    "    subplot_label='B)'\n",
    ")\n",
    "\n",
    "# Fix labels for Boolean values in subplot B\n",
    "current_labels = [label.get_text() for label in ax1.get_xticklabels()]\n",
    "new_labels_b = []\n",
    "for label in current_labels:\n",
    "    if 'Yes' in label:\n",
    "        new_labels_b.append(label.replace('Yes', 'Internal'))\n",
    "    elif 'No' in label:\n",
    "        new_labels_b.append(label.replace('No', 'External'))\n",
    "    else:\n",
    "        new_labels_b.append(label)\n",
    "ax1.set_xticklabels(new_labels_b, fontsize=10, rotation=0)\n",
    "\n",
    "# (C) Additional degree vs No additional degree\n",
    "ax2 = create_stacked_bar_subplot(\n",
    "    axes[2],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='extra_degree',\n",
    "    y_col='salary_ordinal',\n",
    "    order=[True, False],\n",
    "    pairs=[(True, False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Additional Degree (MS, PhD, etc.)',\n",
    "    xlabel='Has Additional Degree',\n",
    "    subplot_label='C)'\n",
    ")\n",
    "\n",
    "# Fix labels for Boolean values in subplot C\n",
    "current_labels = [label.get_text() for label in ax2.get_xticklabels()]\n",
    "new_labels_c = []\n",
    "for label in current_labels:\n",
    "    if 'Yes' in label:\n",
    "        new_labels_c.append(label.replace('Yes', 'Additional Degree'))\n",
    "    elif 'No' in label:\n",
    "        new_labels_c.append(label.replace('No', 'No Additional Degree'))\n",
    "    else:\n",
    "        new_labels_c.append(label)\n",
    "ax2.set_xticklabels(new_labels_c, fontsize=14, rotation=0)\n",
    "\n",
    "# (D) Multiple offers vs Single offer\n",
    "ax3 = create_stacked_bar_subplot(\n",
    "    axes[3],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='multiple_interviews',  # Assuming this should be 'multiple_offers' based on your description\n",
    "    y_col='salary_ordinal',\n",
    "    order=[True, False],\n",
    "    pairs=[(True, False)],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Multiple Offers vs Single Offer',\n",
    "    xlabel='Received Multiple Offers',\n",
    "    subplot_label='D)'\n",
    ")\n",
    "\n",
    "# Fix labels for Boolean values in subplot D\n",
    "current_labels = [label.get_text() for label in ax3.get_xticklabels()]\n",
    "new_labels_d = []\n",
    "for label in current_labels:\n",
    "    if 'Yes' in label:\n",
    "        new_labels_d.append(label.replace('Yes', 'Multiple Offers'))\n",
    "    elif 'No' in label:\n",
    "        new_labels_d.append(label.replace('No', 'Single Offer'))\n",
    "    else:\n",
    "        new_labels_d.append(label)\n",
    "ax3.set_xticklabels(new_labels_d, fontsize=14, rotation=0)\n",
    "\n",
    "# (E) Cost of living by geographic region\n",
    "ax4 = create_stacked_bar_subplot(\n",
    "    axes[4],\n",
    "    data=df_combined_standardized,\n",
    "    x_col='cost_of_living_simple',\n",
    "    y_col='salary_ordinal',\n",
    "    order=['Low', 'Medium', 'High'],\n",
    "    pairs=[('Low', 'Medium'), ('Low', 'High'), ('Medium', 'High')],\n",
    "    test='Mann-Whitney',\n",
    "    loc='inside',\n",
    "    text_format='simple',\n",
    "    title='Cost of Living by Geographic Region',\n",
    "    xlabel='Cost of Living',\n",
    "    subplot_label='E)'\n",
    ")\n",
    "\n",
    "# Hide the axes and spines for the empty subplot (bottom right - position 5 in 3x2 grid)\n",
    "axes[5].axis('off')\n",
    "\n",
    "# Create legend in the empty subplot space (row 3, column 2)\n",
    "# Get legend handles and labels from the first subplot\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "\n",
    "# Create legend in the empty axes[5] space\n",
    "legend = axes[5].legend(reversed(handles), reversed(labels), \n",
    "                       title='Salary Range',\n",
    "                       loc='center',\n",
    "                       fontsize=14,\n",
    "                       title_fontsize=16,\n",
    "                       frameon=True,\n",
    "                       fancybox=True,\n",
    "                       shadow=False,\n",
    "                       handlelength=2.5,\n",
    "                       handletextpad=1.0,\n",
    "                       columnspacing=2.0,\n",
    "                       borderpad=1.5)\n",
    "\n",
    "# Make legend title bold\n",
    "legend.get_title().set_fontweight('bold')\n",
    "\n",
    "# Adjust layout to optimize spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('fig_salary_distribution_subplots.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TableOne: Combined Salary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['gender', 'job_type', 'internal_offer', 'salary_range', 'salary_ordinal','extra_degree',\n",
    "       'multiple_interviews', 'geographic_region_simple','geographic_region', \n",
    "       'cost_of_living',\n",
    "        'cost_of_living_simple',\n",
    "       'cost_of_living_categorical',\n",
    "       'has_bonuses', 'bonus_value', ]\n",
    "\n",
    "\n",
    "\n",
    "# Generate TableOne\n",
    "table1 = TableOne(df_combined_standardized, columns=columns, categorical=columns,  rename=None, groupby='job_type', pval=True, missing=False)\n",
    "table1.to_csv('table1_job_offers_PS_CE.csv')\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
